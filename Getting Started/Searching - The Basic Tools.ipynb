{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch: The Definitive Guide - Python\n",
    "\n",
    "Following the examples in the book, here are Python snippets that achieve the same effect.\n",
    "\n",
    "Documentation for the Python libs:\n",
    "\n",
    "Low-level API:\n",
    "\n",
    "https://elasticsearch-py.readthedocs.io/en/master/index.html\n",
    "\n",
    "Expressive DSL API (more \"Pythonic\")\n",
    "\n",
    "http://elasticsearch-dsl.readthedocs.io/en/latest/index.html\n",
    "\n",
    "Github repo for DSL API:\n",
    "\n",
    "https://github.com/elastic/elasticsearch-dsl-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q\n",
    "from pprint import pprint\n",
    "\n",
    "es = Elasticsearch(\n",
    "    'localhost',\n",
    "    # sniff before doing anything\n",
    "    sniff_on_start=True,\n",
    "    # refresh nodes after a node fails to respond\n",
    "    sniff_on_connection_fail=True,\n",
    "    # and also every 60 seconds\n",
    "    sniffer_timeout=60\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empty Search\n",
    "From: https://www.elastic.co/guide/en/elasticsearch/guide/master/empty-search.html\n",
    "\n",
    ">GET _search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = es.search('_all') # same as es.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from pprint import pprint\n",
    "#pprint(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(.kibana/index-pattern/megacorp): {'title': 'megacorp', 'fields': '[{\"name\":\"last_name.keyword...}>, <Hit(.kibana/index-pattern/website): {'title': 'website', 'fields': '[{\"name\":\"date\",\"type\":\"date...}>, <Hit(.kibana/config/5.2.2): {'buildNum': 14723, 'defaultIndex': 'megacorp', 'discover:ag...}>, <Hit(us/tweet/14): {'name': 'John Smith', 'user_id': 1, 'date': '2014-09-24', '...}>, <Hit(gb/tweet/5): {'name': 'Mary Jones', 'user_id': 2, 'date': '2014-09-15', '...}>, <Hit(gb/tweet/9): {'name': 'Mary Jones', 'user_id': 2, 'date': '2014-09-19', '...}>, <Hit(us/tweet/8): {'name': 'John Smith', 'user_id': 1, 'date': '2014-09-18'}>, <Hit(us/tweet/10): {'name': 'John Smith', 'user_id': 1, 'date': '2014-09-20', '...}>, <Hit(us/tweet/12): {'name': 'John Smith', 'user_id': 1, 'date': '2014-09-22', '...}>, <Hit(email/messages/2): {'title': 'how to make millions', 'tag': ['priority', 'read'...}>]>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Search(using=es)\n",
    "response = s.execute()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With timeout:\n",
    "\n",
    ">GET /_search?timeout=10ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = es.search('_all', timeout='10ms') # same as es.search(timeout='10ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Hit(.kibana/index-pattern/megacorp): {'title': 'megacorp', 'fields': '[{\"name\":\"last_name.keyword...}>\n",
      "<Hit(.kibana/index-pattern/website): {'title': 'website', 'fields': '[{\"name\":\"date\",\"type\":\"date...}>\n",
      "<Hit(.kibana/config/5.2.2): {'buildNum': 14723, 'defaultIndex': 'megacorp', 'discover:ag...}>\n",
      "<Hit(us/tweet/14): {'name': 'John Smith', 'user_id': 1, 'date': '2014-09-24', '...}>\n",
      "<Hit(gb/tweet/5): {'name': 'Mary Jones', 'user_id': 2, 'date': '2014-09-15', '...}>\n",
      "<Hit(gb/tweet/9): {'name': 'Mary Jones', 'user_id': 2, 'date': '2014-09-19', '...}>\n",
      "<Hit(us/tweet/8): {'name': 'John Smith', 'user_id': 1, 'date': '2014-09-18'}>\n",
      "<Hit(us/tweet/10): {'name': 'John Smith', 'user_id': 1, 'date': '2014-09-20', '...}>\n",
      "<Hit(us/tweet/12): {'name': 'John Smith', 'user_id': 1, 'date': '2014-09-22', '...}>\n",
      "<Hit(email/messages/2): {'title': 'how to make millions', 'tag': ['priority', 'read'...}>\n"
     ]
    }
   ],
   "source": [
    "# To see the results, we can iterate:\n",
    "# Elasticsearch pages the results (to 10 hits)\n",
    "for hit in s:\n",
    "    print(hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-index, Multitype\n",
    "\n",
    "First using the low-level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "#/_search\n",
    "#Search all types in all indices\n",
    "res = es.search('_all')\n",
    "\n",
    "#/gb/_search\n",
    "#Search all types in the gb index\n",
    "res = es.search(index='gb')\n",
    "\n",
    "#/gb,us/_search\n",
    "#Search all types in the gb and us indices\n",
    "res = es.search(index=['gb','us'])\n",
    "\n",
    "#/g*,u*/_search\n",
    "#Search all types in any indices beginning with g or beginning with u\n",
    "res = es.search(index=['g*','u*'])\n",
    "\n",
    "#/gb/user/_search\n",
    "#Search type user in the gb index\n",
    "res = es.search(index='gb', doc_type='user')\n",
    "\n",
    "#/gb,us/user,tweet/_search\n",
    "#Search types user and tweet in the gb and us indices\n",
    "res = es.search(index=['g*','u*'], doc_type=['user', 'tweet'])\n",
    "print(res['hits']['total'])\n",
    "\n",
    "#/_all/user,tweet/_search\n",
    "#Search types user and tweet in all indices\n",
    "res = es.search(doc_type=['user', 'tweet'])\n",
    "print(res['hits']['total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next using the DSL, although similar for such basic searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#/_search\n",
    "#Search all types in all indices\n",
    "s = Search(using=es)\n",
    "response = s.execute()\n",
    "\n",
    "#/gb/_search\n",
    "#Search all types in the gb index\n",
    "s = Search(using=es, index='gb')\n",
    "response = s.execute()\n",
    "\n",
    "#/gb,us/_search\n",
    "#Search all types in the gb and us indices\n",
    "s = Search(using=es, index=['gb','us'])\n",
    "response = s.execute()\n",
    "\n",
    "#/g*,u*/_search\n",
    "#Search all types in any indices beginning with g or beginning with u\n",
    "s = Search(using=es, index=['g*','u*'])\n",
    "response = s.execute()\n",
    "\n",
    "#/gb/user/_search\n",
    "#Search type user in the gb index\n",
    "s = Search(using=es, index=['g*','u*'], doc_type='user')\n",
    "response = s.execute()\n",
    "\n",
    "\n",
    "#/gb,us/user,tweet/_search\n",
    "#Search types user and tweet in the gb and us indices\n",
    "s = Search(using=es, index=['g*','u*'], doc_type=['user','tweet'])\n",
    "response = s.execute()\n",
    "\n",
    "#/_all/user,tweet/_search\n",
    "#Search types user and tweet in all indices\n",
    "s = Search(using=es, doc_type=['user','tweet'])\n",
    "response = s.execute()\n",
    "print(response.hits.total)\n",
    "print(len(res['hits']['hits']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pagination\n",
    "\n",
    "The last search produced a hits total of 14, but there are only 10 documents in the array.\n",
    "\n",
    "This is due to pagination, so we need to use pointers:\n",
    "\n",
    ">GET /_search?size=5\n",
    "\n",
    ">GET /_search?size=5&from=5\n",
    "\n",
    ">GET /_search?size=5&from=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For search API:\n",
    "res = es.search(doc_type=['user', 'tweet'], from_=5, size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(res['hits']['total'])\n",
    "print(len(res['hits']['hits']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Lite\n",
    "\n",
    "These initial searches all use the Lucene Query String Syntax.\n",
    "\n",
    ">GET /_all/tweet/_search?q=tweet:elasticsearch\n",
    "\n",
    "For the low-level API, we use the q parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits:7\n",
      "\n",
      "{'_id': '6',\n",
      " '_index': 'us',\n",
      " '_score': 0.6395861,\n",
      " '_source': {'date': '2014-09-16',\n",
      "             'name': 'John Smith',\n",
      "             'tweet': 'The Elasticsearch API is really easy to use',\n",
      "             'user_id': 1},\n",
      " '_type': 'tweet'}\n"
     ]
    }
   ],
   "source": [
    "res = es.search(doc_type=['tweet'], q='tweet:elasticsearch')\n",
    "print('Total hits:{}\\n'.format(res['hits']['total']))\n",
    "pprint(res['hits']['hits'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the DSL, the intended purpose is to avoid the query string syntax and use the query string language instead. For completeness, here is an equivalent script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits:7\n",
      "\n",
      "{'score': 0.6395861, 'index': 'us', 'doc_type': 'tweet', 'id...}\n"
     ]
    }
   ],
   "source": [
    "s = Search(using=es, doc_type=['tweet']) \\\n",
    "    .query('match', tweet='elasticsearch')\n",
    "response = s.execute()\n",
    "print('Total hits:{}\\n'.format(response.hits.total))\n",
    "pprint(response[0].meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, notice that the pprint has not given us the same JSON response as the above query string syntax result via the low-level API. This is because the Search() object returns an array of Hit objects. These are constructed so as to expose the individual fields as object attributes (__getattr__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Elasticsearch API is really easy to use\n",
      "However did I manage before Elasticsearch?\n",
      "So yes, I am an Elasticsearch fanboy\n",
      "Elasticsearch is built for the cloud, easy to scale\n",
      "Elasticsearch surely is one of the hottest new NoSQL products\n",
      "Elasticsearch means full text search has never been so easy\n",
      "Elasticsearch and I have left the honeymoon stage, and I still love her.\n"
     ]
    }
   ],
   "source": [
    "for hit in response:\n",
    "    print(hit.tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The _all field\n",
    "\n",
    "> GET /_search?q=mary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits:8\n",
      "\n",
      "{'_id': '4',\n",
      " '_index': 'us',\n",
      " '_score': 0.6650044,\n",
      " '_source': {'date': '2014-09-14',\n",
      "             'name': 'John Smith',\n",
      "             'tweet': '@mary it is not just text, it does everything',\n",
      "             'user_id': 1},\n",
      " '_type': 'tweet'}\n"
     ]
    }
   ],
   "source": [
    "res = es.search(q='mary')\n",
    "print('Total hits:{}\\n'.format(res['hits']['total']))\n",
    "pprint(res['hits']['hits'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the DSL, we need to call the _all field explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits:8\n",
      "\n",
      "@mary it is not just text, it does everything\n"
     ]
    }
   ],
   "source": [
    "s = Search(using=es) \\\n",
    "    .query('match', _all='mary')\n",
    "response = s.execute()\n",
    "print('Total hits:{}\\n'.format(response.hits.total))\n",
    "print(response[0].tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> +name:(mary john) +date:>2014-09-10 +(aggregations geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits:1\n",
      "\n",
      "{'_id': '9',\n",
      " '_index': 'gb',\n",
      " '_score': 2.3835227,\n",
      " '_source': {'date': '2014-09-19',\n",
      "             'name': 'Mary Jones',\n",
      "             'tweet': 'Geo-location aggregations are really cool',\n",
      "             'user_id': 2},\n",
      " '_type': 'tweet'}\n"
     ]
    }
   ],
   "source": [
    "res = es.search(q='+name:(mary john) +date:>2014-09-10 +(aggregations geo)')\n",
    "print('Total hits:{}\\n'.format(res['hits']['total']))\n",
    "pprint(res['hits']['hits'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
