{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch: The Definitive Guide - Python\n",
    "\n",
    "Following the examples in the book, here are Python snippets that achieve the same effect.\n",
    "\n",
    "Documentation for the Python libs:\n",
    "\n",
    "Low-level API:\n",
    "\n",
    "https://elasticsearch-py.readthedocs.io/en/master/index.html\n",
    "\n",
    "Expressive DSL API (more \"Pythonic\")\n",
    "\n",
    "http://elasticsearch-dsl.readthedocs.io/en/latest/index.html\n",
    "\n",
    "Github repo for DSL API:\n",
    "\n",
    "https://github.com/elastic/elasticsearch-dsl-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 items created\n"
     ]
    }
   ],
   "source": [
    "import index\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q\n",
    "from pprint import pprint\n",
    "\n",
    "es = Elasticsearch(\n",
    "    'localhost',\n",
    "    # sniff before doing anything\n",
    "    sniff_on_start=True,\n",
    "    # refresh nodes after a node fails to respond\n",
    "    sniff_on_connection_fail=True,\n",
    "    # and also every 60 seconds\n",
    "    sniffer_timeout=60\n",
    ")\n",
    "\n",
    "r = index.populate()\n",
    "print('{} items created'.format(len(r['items'])))\n",
    "\n",
    "# Let's repopulate the index as we deleted 'gb' in earlier chapters:\n",
    "# Run the script: populate.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Sorting and Relevance\n",
    "\n",
    "By default, results are returned sorted by relevance—with the most relevant docs first. Later in this chapter, we explain what we mean by relevance and how it is calculated, but let’s start by looking at the sort parameter and how to use it.\n",
    "\n",
    "Relevance isn't always meaningful e.g. if we are mostly filtering:\n",
    "\n",
    "```\n",
    "GET /_search\n",
    "{\n",
    "    \"query\" : {\n",
    "        \"bool\" : {\n",
    "            \"filter\" : {\n",
    "                \"term\" : {\n",
    "                    \"user_id\" : 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And a filter-only search\n",
    "s = Search(using=es)\n",
    "s = s.filter('term', user_id=1)\n",
    "res = s.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docs returned in random order and will have a _score of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:0.0\n",
      "Score:0.0\n",
      "Score:0.0\n",
      "Score:0.0\n",
      "Score:0.0\n",
      "Score:0.0\n"
     ]
    }
   ],
   "source": [
    "for hit in res:\n",
    "    print('Score:{}'.format(hit.meta.score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(us/tweet/14): {'date': '2014-09-24', 'tweet': 'How many more cheesy tweets...}>, <Hit(us/tweet/8): {'date': '2014-09-18', 'user_id': 1, 'name': 'John Smith'}>, <Hit(us/tweet/10): {'date': '2014-09-20', 'tweet': 'Elasticsearch surely is one...}>, <Hit(us/tweet/12): {'date': '2014-09-22', 'tweet': 'Elasticsearch and I have le...}>, <Hit(us/tweet/4): {'date': '2014-09-14', 'tweet': '@mary it is not just text, ...}>, <Hit(us/tweet/6): {'date': '2014-09-16', 'tweet': 'The Elasticsearch API is re...}>]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or we can make sure the items have a constant non-zero score\n",
    "s = Search(using=es).query('constant_score', filter=Q('term', user_id=1))\n",
    "res = s.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:1.0 with date of 2014-09-24\n",
      "Score:1.0 with date of 2014-09-18\n",
      "Score:1.0 with date of 2014-09-20\n",
      "Score:1.0 with date of 2014-09-22\n",
      "Score:1.0 with date of 2014-09-14\n",
      "Score:1.0 with date of 2014-09-16\n"
     ]
    }
   ],
   "source": [
    "for hit in res:\n",
    "    print('Score:{} with date of {}'.format(hit.meta.score,hit.date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting by Field Values\n",
    "\n",
    "```\n",
    "GET /_search\n",
    "{\n",
    "    \"query\" : {\n",
    "        \"bool\" : {\n",
    "            \"filter\" : { \"term\" : { \"user_id\" : 1 }}\n",
    "        }\n",
    "    },\n",
    "    \"sort\": { \"date\": { \"order\": \"desc\" }}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:None with date of 2014-09-24 and sort field:[1411516800000]\n",
      "Score:None with date of 2014-09-22 and sort field:[1411344000000]\n",
      "Score:None with date of 2014-09-20 and sort field:[1411171200000]\n",
      "Score:None with date of 2014-09-18 and sort field:[1410998400000]\n",
      "Score:None with date of 2014-09-16 and sort field:[1410825600000]\n",
      "Score:None with date of 2014-09-14 and sort field:[1410652800000]\n"
     ]
    }
   ],
   "source": [
    "s = Search(using=es).query('bool', filter=Q('term', user_id=1))\n",
    "s = s.sort({ \"date\": { \"order\": \"desc\" }})\n",
    "res = s.execute()\n",
    "# Now is date descending order:\n",
    "for hit in res:\n",
    "    print('Score:{} with date of {} and sort field:{}'\n",
    "          .format(hit.meta.score,hit.date,hit.meta.sort))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the score field set to None because it isn't required (due to a sort) and the addition of a \"sort\" field that was indexed internally and used to perform the sort (here in milliseconds since the epoch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilevel Sorting\n",
    "\n",
    "```\n",
    "GET /_search\n",
    "{\n",
    "    \"query\" : {\n",
    "        \"bool\" : {\n",
    "            \"must\":   { \"match\": { \"tweet\": \"manage text search\" }},\n",
    "            \"filter\" : { \"term\" : { \"user_id\" : 2 }}\n",
    "        }\n",
    "    },\n",
    "    \"sort\": [\n",
    "        { \"date\":   { \"order\": \"desc\" }},\n",
    "        { \"_score\": { \"order\": \"desc\" }}\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = Search(using=es).query('bool', \n",
    "                           must=Q('match', tweet='manage text search'),\n",
    "                           filter=Q('term', user_id=2))\n",
    "s = s.sort({ \"date\":   { \"order\": \"desc\" }}, { \"_score\": { \"order\": \"desc\" }})\n",
    "#s = s.sort(\"date\",\"_score\") # sorted by date first\n",
    "res = s.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:0.64433396 with date of 2014-09-15 and sort field:[1410739200000, 0.64433396]\n",
      "Score:1.3434829 with date of 2014-09-13 and sort field:[1410566400000, 1.3434829]\n"
     ]
    }
   ],
   "source": [
    "for hit in res:\n",
    "    print('Score:{} with date of {} and sort field:{}'\n",
    "          .format(hit.meta.score,hit.date,hit.meta.sort))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order is important. Results are sorted by the first criterion first. Only results whose first sort value is identical will then be sorted by the second criterion, and so on.\n",
    "\n",
    "Multilevel sorting doesn’t have to involve the _score. You could sort by using several different fields, on geo-distance or on a custom value calculated in a script.\n",
    "\n",
    "#### Sorting on Multivalue Fields\n",
    "\n",
    "Let's say we have fields with more than one item. How do we sort on them? For numbers and dates, you can reduce a multivalue field to a single value by using the min, max, avg, or sum sort modes. For instance, you could sort on the earliest date in each dates field by using the following:\n",
    "\n",
    "```\n",
    "\"sort\": {\n",
    "    \"dates\": {\n",
    "        \"order\": \"asc\",\n",
    "        \"mode\":  \"min\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Let's create some docs to try this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '2',\n",
       " '_index': 'shows',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'tv_series',\n",
       " '_version': 1,\n",
       " 'created': True,\n",
       " 'result': 'created'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = {\n",
    "    'title': 'How I Met Your Mother',\n",
    "    'date': '2013-01-01',\n",
    "    'ratings': [2,3,1,3,4,5,5,5,3,4,2]\n",
    "}\n",
    "doc2 = {\n",
    "    'title': 'Breaking Bad',\n",
    "    'date': '2013-01-01',\n",
    "    'ratings': [5,5,4,3,4,5,5,5,3,5,5]\n",
    "}\n",
    "es.create(index='shows', doc_type='tv_series', body=doc1, id=1)\n",
    "es.create(index='shows', doc_type='tv_series', body=doc2, id=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = Search(using=es)\n",
    "s = s.sort({ \"ratings\":   { \"order\": \"desc\", \"mode\":\"avg\" }})\n",
    "#s = s.sort(\"date\",\"_score\") # sorted by date first\n",
    "res = s.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for hit in res:\n",
    "    print(hit.title, hit.meta.sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Sorting and Multifields\n",
    "\n",
    "Sorting on text fields is problematic because an analyzed field will consist of a bunch of tokens (post analyzer). If you really want to sort on a text field, then it's best left in an unanalyzed form. This can be done by adding a field:\n",
    "\n",
    "```\n",
    "\"tweet\": { \n",
    "    \"type\":     \"string\",\n",
    "    \"analyzer\": \"english\",\n",
    "    \"fields\": {\n",
    "        \"raw\": { \n",
    "            \"type\":  \"string\",\n",
    "            \"index\": \"not_analyzed\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "And then sort on the raw field:\n",
    "\n",
    "```\n",
    "GET /_search\n",
    "{\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"tweet\": \"elasticsearch\"\n",
    "        }\n",
    "    },\n",
    "    \"sort\": \"tweet.raw\"\n",
    "}\n",
    "```\n",
    "\n",
    "First I will delete the tweet index and re-create using template 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = index.populate(template=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = Search(using=es).query(Q('match', tweet='elasticsearch'))\n",
    "s = s.sort(\"tweet.raw\")\n",
    "res = s.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for hit in res:\n",
    "    print(hit.meta.sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Relevance?\n",
    "\n",
    "The relevance score of each document is represented by a positive floating-point number called the _score. The higher the _score, the more relevant the document.\n",
    "\n",
    "A query clause generates a _score for each document. How that score is calculated depends on the type of query clause. Different query clauses are used for different purposes: a fuzzy query might determine the _score by calculating how similar the spelling of the found word is to the original search term; a terms query would incorporate the percentage of terms that were found. However, what we usually mean by relevance is the algorithm that we use to calculate how similar the contents of a full-text field are to a full-text query string.\n",
    "\n",
    "The standard similarity algorithm used in Elasticsearch is known as term frequency/inverse document frequency, or [TF/IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
    "\n",
    "Understanding how the relevance was calculated can be difficult to understand, hence the availability of the explain parameter.\n",
    "\n",
    "```\n",
    "GET /_search?explain \n",
    "{\n",
    "   \"query\"   : { \"match\" : { \"tweet\" : \"honeymoon\" }}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = Search(using=es).query(Q('match', tweet='honeymoon'))\n",
    "s = s.extra(explain=True)\n",
    "res = s.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"1873ba03-527b-44f2-b271-02475a2091f5\" style=\"height: 600px; width:100%;\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        require([\"https://rawgit.com/caldwell/renderjson/master/renderjson.js\"], function() {\n",
       "        document.getElementById('1873ba03-527b-44f2-b271-02475a2091f5').appendChild(renderjson([{'_score': 0.6395861, '_type': 'tweet', '_node': 'nKjjkxx5SfWhB1vabVu5ig', '_source': {'date': '2014-09-22', 'tweet': 'Elasticsearch and I have left the honeymoon stage, and I still love her.', 'user_id': 1, 'name': 'John Smith'}, '_id': '12', '_index': 'us', '_shard': '[us][1]', '_explanation': {'details': [{'details': [{'details': [{'details': [], 'value': 1.0, 'description': 'docFreq'}, {'details': [], 'value': 2.0, 'description': 'docCount'}], 'value': 0.6931472, 'description': 'idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:'}, {'details': [{'details': [], 'value': 1.0, 'description': 'termFreq=1.0'}, {'details': [], 'value': 1.2, 'description': 'parameter k1'}, {'details': [], 'value': 0.75, 'description': 'parameter b'}, {'details': [], 'value': 8.5, 'description': 'avgFieldLength'}, {'details': [], 'value': 10.24, 'description': 'fieldLength'}], 'value': 0.9227277, 'description': 'tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:'}], 'value': 0.6395861, 'description': 'score(doc=2,freq=1.0 = termFreq=1.0\\n), product of:'}], 'value': 0.6395861, 'description': 'weight(tweet:honeymoon in 2) [PerFieldSimilarity], result of:'}}]))\n",
       "        });\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index.RenderJSON(res['hits']['hits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = Search(using=es).query(Q('match', tweet='honeymoon') & Q('match', _id=12))\n",
    "s = s.extra(explain=True)\n",
    "res = s.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"8748946e-0bb8-48ec-b4c1-ac03e0cd3026\" style=\"height: 600px; width:100%;\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        require([\"https://rawgit.com/caldwell/renderjson/master/renderjson.js\"], function() {\n",
       "        document.getElementById('8748946e-0bb8-48ec-b4c1-ac03e0cd3026').appendChild(renderjson([{'_score': 1.6395861, '_type': 'tweet', '_node': 'nKjjkxx5SfWhB1vabVu5ig', '_source': {'date': '2014-09-22', 'tweet': 'Elasticsearch and I have left the honeymoon stage, and I still love her.', 'user_id': 1, 'name': 'John Smith'}, '_id': '12', '_index': 'us', '_shard': '[us][1]', '_explanation': {'details': [{'details': [{'details': [{'details': [{'details': [], 'value': 1.0, 'description': 'docFreq'}, {'details': [], 'value': 2.0, 'description': 'docCount'}], 'value': 0.6931472, 'description': 'idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:'}, {'details': [{'details': [], 'value': 1.0, 'description': 'termFreq=1.0'}, {'details': [], 'value': 1.2, 'description': 'parameter k1'}, {'details': [], 'value': 0.75, 'description': 'parameter b'}, {'details': [], 'value': 8.5, 'description': 'avgFieldLength'}, {'details': [], 'value': 10.24, 'description': 'fieldLength'}], 'value': 0.9227277, 'description': 'tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:'}], 'value': 0.6395861, 'description': 'score(doc=2,freq=1.0 = termFreq=1.0\\n), product of:'}], 'value': 0.6395861, 'description': 'weight(tweet:honeymoon in 2) [PerFieldSimilarity], result of:'}, {'details': [{'details': [], 'value': 1.0, 'description': 'boost'}, {'details': [], 'value': 1.0, 'description': 'queryNorm'}], 'value': 1.0, 'description': 'ConstantScore(_uid:tweet#12 _uid:user#12), product of:'}], 'value': 1.6395861, 'description': 'sum of:'}}]))\n",
       "        });\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index.RenderJSON(res['hits']['hits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
