{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch: The Definitive Guide - Python\n",
    "\n",
    "Following the examples in the book, here are Python snippets that achieve the same effect.\n",
    "\n",
    "Documentation for the Python libs:\n",
    "\n",
    "Low-level API:\n",
    "\n",
    "https://elasticsearch-py.readthedocs.io/en/master/index.html\n",
    "\n",
    "Expressive DSL API (more \"Pythonic\")\n",
    "\n",
    "http://elasticsearch-dsl.readthedocs.io/en/latest/index.html\n",
    "\n",
    "Github repo for DSL API:\n",
    "\n",
    "https://github.com/elastic/elasticsearch-dsl-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 items created\n"
     ]
    }
   ],
   "source": [
    "import index\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q, Index\n",
    "from pprint import pprint\n",
    "\n",
    "es = Elasticsearch(\n",
    "    'localhost',\n",
    "    # sniff before doing anything\n",
    "    sniff_on_start=True,\n",
    "    # refresh nodes after a node fails to respond\n",
    "    sniff_on_connection_fail=True,\n",
    "    # and also every 60 seconds\n",
    "    sniffer_timeout=60\n",
    ")\n",
    "\n",
    "r = index.load_sid_examples(settings={ \"settings\": { \"number_of_shards\": 1 }},set=3)\n",
    "print('{} items created'.format(len(r['items'])))\n",
    "\n",
    "# Let's repopulate the index as we deleted 'gb' in earlier chapters:\n",
    "# Run the script: populate.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Multifield Search\n",
    "\n",
    "Queries are seldom simple one-clause match queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if es.indices.exists('books'):\n",
    "    es.indices.delete('books')\n",
    "es.indices.create(index='books',\n",
    "                     body={ \"settings\": { \"number_of_shards\": 1 }})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "body = {\n",
    "    \"title\": \"War and Peace\",\n",
    "    \"author\": \"Leo Tolstoy\",\n",
    "    \"translator\": \"Constance Garnett\"\n",
    "}\n",
    "r = es.create(index='books', doc_type='classics', body=body, id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "body = {\n",
    "    \"title\": \"War and Peace\",\n",
    "    \"author\": \"Leo Tolstoy\",\n",
    "    \"translator\": \"Louise Maude\"\n",
    "}\n",
    "r = es.create(index='books', doc_type='classics', body=body, id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "body = {\n",
    "    \"title\": \"War and Peace\",\n",
    "    \"author\": \"Leo Tolstoy\",\n",
    "    \"format\" : \"hardback\"\n",
    "}\n",
    "r = es.create(index='books', doc_type='classics', body=body, id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = Index('books', using=es).search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = Q('bool',\n",
    "         should=[Q('match', title={ \"query\": \"War and Peace\", \"boost\": 2}),\n",
    "                 Q('match', author={ \"query\": \"Leo Tolstoy\", \"boost\": 2}),\n",
    "                 Q('bool',\n",
    "                      should=[Q('match', translator=\"Constance Garnett\"),\n",
    "                              Q('match', translater='Louise Maude')])]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bool': {'should': [{'match': {'title': {'boost': 2,\n",
      "                                          'query': 'War and Peace'}}},\n",
      "                     {'match': {'author': {'boost': 2,\n",
      "                                           'query': 'Leo Tolstoy'}}},\n",
      "                     {'bool': {'should': [{'match': {'translator': 'Constance '\n",
      "                                                                   'Garnett'}},\n",
      "                                          {'match': {'translater': 'Louise '\n",
      "                                                                   'Maude'}}]}}]}}\n"
     ]
    }
   ],
   "source": [
    "pprint(q.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2.4280977\n",
      "2 1.1842774\n",
      "3 1.1842774\n"
     ]
    }
   ],
   "source": [
    "s = s.query(q)\n",
    "res = s.execute()\n",
    "for hit in res:\n",
    "    print(hit.meta.id, hit.meta.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if es.indices.exists('my_index'):\n",
    "    es.indices.delete('my_index')\n",
    "es.indices.create(index='my_index',\n",
    "                     body={ \"settings\": { \"number_of_shards\": 1 }})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "body = {\n",
    "    \"title\": \"Quick brown rabbits\",\n",
    "    \"body\":  \"Brown rabbits are commonly seen.\"\n",
    "}\n",
    "r = es.create(index='my_index', doc_type='my_type', body=body, id=1)\n",
    "body = {\n",
    "    \"title\": \"Keeping pets healthy\",\n",
    "    \"body\":  \"My quick brown fox eats rabbits on a regular basis.\"\n",
    "}\n",
    "r = es.create(index='my_index', doc_type='my_type', body=body, id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Quick brown rabbits 0.8181274\n",
      "2 Keeping pets healthy 0.7616384\n"
     ]
    }
   ],
   "source": [
    "s = Index('my_index', using=es).search()\n",
    "s = s.query(Q('bool',\n",
    "                 should=[Q('match', title=\"Brown fox\"),\n",
    "                         Q('match', body=\"Brown fox\")]))\n",
    "s = s.extra(explain=True)\n",
    "res = s.execute()\n",
    "for hit in res:\n",
    "    print(hit.meta.id, hit.title, hit.meta.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Keeping pets healthy 0.7616384\n",
      "1 Quick brown rabbits 0.6099695\n"
     ]
    }
   ],
   "source": [
    "s = Index('my_index', using=es).search()\n",
    "q = Q('dis_max',\n",
    "                 queries=[Q('match', title=\"Brown fox\").to_dict(),\n",
    "                         Q('match', body=\"Brown fox\").to_dict()])\n",
    "s = s.query(q)\n",
    "res = s.execute()\n",
    "for hit in res:\n",
    "    print(hit.meta.id, hit.title, hit.meta.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Best Fields Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Quick brown rabbits 0.6099695\n",
      "2 Keeping pets healthy 0.6099695\n"
     ]
    }
   ],
   "source": [
    "s = Index('my_index', using=es).search()\n",
    "q = Q('dis_max',\n",
    "                 queries=[Q('match', title=\"Quick pets\").to_dict(),\n",
    "                         Q('match', body=\"Quick pets\").to_dict()])\n",
    "s = s.query(q)\n",
    "s = s.extra(explain=True)\n",
    "res = s.execute()\n",
    "for hit in res:\n",
    "    print(hit.meta.id, hit.title, hit.meta.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dis-max` only takes into the account the best scoring fields from each doc. In this case, they are the same. In this case (a tie-breaker) we take the _score from the other matching clauses into account, by specifying the tie_breaker parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Keeping pets healthy 0.7908763\n",
      "1 Quick brown rabbits 0.6099695\n"
     ]
    }
   ],
   "source": [
    "s = Index('my_index', using=es).search()\n",
    "q = Q('dis_max',\n",
    "                 queries=[Q('match', title=\"Quick pets\").to_dict(),\n",
    "                         Q('match', body=\"Quick pets\").to_dict()],\n",
    "     tie_breaker=0.3)\n",
    "s = s.query(q)\n",
    "s = s.extra(explain=True)\n",
    "res = s.execute()\n",
    "for hit in res:\n",
    "    print(hit.meta.id, hit.title, hit.meta.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tie_breaker parameter makes the dis_max query behave more like a halfway house between dis_max and bool. It changes the score calculation as follows:\n",
    "\n",
    "Take the _score of the best-matching clause.\n",
    "Multiply the score of each of the other matching clauses by the tie_breaker.\n",
    "Add them all together and normalize.\n",
    "With the tie_breaker, all matching clauses count, but the best-matching clause counts most.\n",
    "\n",
    "#### Multi-match queries\n",
    "\n",
    "We can re-write a query like this:\n",
    "\n",
    "`\n",
    "{\n",
    "  \"dis_max\": {\n",
    "    \"queries\":  [\n",
    "      {\n",
    "        \"match\": {\n",
    "          \"title\": {\n",
    "            \"query\": \"Quick brown fox\",\n",
    "            \"minimum_should_match\": \"30%\"\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"match\": {\n",
    "          \"body\": {\n",
    "            \"query\": \"Quick brown fox\",\n",
    "            \"minimum_should_match\": \"30%\"\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "    ],\n",
    "    \"tie_breaker\": 0.3\n",
    "  }\n",
    "}`\n",
    "\n",
    "more concisely as this:\n",
    "\n",
    "`\n",
    "{\n",
    "    \"multi_match\": {\n",
    "        \"query\":                \"Quick brown fox\",\n",
    "        \"type\":                 \"best_fields\", \n",
    "        \"fields\":               [ \"title\", \"body\" ],\n",
    "        \"tie_breaker\":          0.3,\n",
    "        \"minimum_should_match\": \"30%\" \n",
    "    }\n",
    "}\n",
    "`\n",
    "\n",
    "But in Pythonic DSL, it's even more expressive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Keeping pets healthy 0.7908763\n",
      "1 Quick brown rabbits 0.6099695\n"
     ]
    }
   ],
   "source": [
    "s = Index('my_index', using=es).search()\n",
    "q = Q('multi_match', query='Quick pets', fields=['title','body'],\n",
    "      tie_breaker=0.3, type='best_fields')\n",
    "s = s.query(q)\n",
    "res = s.execute()\n",
    "for hit in res:\n",
    "    print(hit.meta.id, hit.title, hit.meta.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Keeping pets healthy 0.7908763\n",
      "1 Quick brown rabbits 0.6099695\n"
     ]
    }
   ],
   "source": [
    "# best_fields is the default type anyway, so can be left out (though less expressive)\n",
    "s = Index('my_index', using=es).search()\n",
    "q = Q('multi_match', query='Quick pets', fields=['title','body'],\n",
    "      tie_breaker=0.3)\n",
    "s = s.query(q)\n",
    "res = s.execute()\n",
    "for hit in res:\n",
    "    print(hit.meta.id, hit.title, hit.meta.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Wildcards in Field Names\n",
    "\n",
    "Below example contrived, but more useful for fields with similar names, like prefixes perhaps: `book_title`, `chapter_title`, and `section_title` fields, with the following:\n",
    "\n",
    "`Q('multi_match', query='Quick brown fox', fields=['*_title'])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Keeping pets healthy 0.7908763\n",
      "1 Quick brown rabbits 0.6099695\n"
     ]
    }
   ],
   "source": [
    "# wouldn't do this, but just for demo\n",
    "s = Index('my_index', using=es).search()\n",
    "q = Q('multi_match', query='Quick pets', fields=['t*','b*'],\n",
    "      tie_breaker=0.3)\n",
    "s = s.query(q)\n",
    "res = s.execute()\n",
    "for hit in res:\n",
    "    print(hit.meta.id, hit.title, hit.meta.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting Individual Fields\n",
    "\n",
    "Individual fields can be boosted by using the caret (^) syntax: just add ^boost after the field name, where boost is a floating-point number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Keeping pets healthy  -  My quick brown fox eats rabbits on a regular basis. 0.7908763\n",
      "1 Quick brown rabbits  -  Brown rabbits are commonly seen. 0.6099695\n"
     ]
    }
   ],
   "source": [
    "# without the boost\n",
    "s = Index('my_index', using=es).search()\n",
    "q = Q('multi_match', query='Quick pets', fields=['title','body'],\n",
    "      tie_breaker=0.3)\n",
    "s = s.query(q)\n",
    "res = s.execute()\n",
    "for hit in res:\n",
    "    print(hit.meta.id, hit.title, ' - ', hit.body, hit.meta.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Keeping pets healthy  -  My quick brown fox eats rabbits on a regular basis. 1.4008458\n",
      "1 Quick brown rabbits  -  Brown rabbits are commonly seen. 1.219939\n"
     ]
    }
   ],
   "source": [
    "# **with** the boost\n",
    "s = Index('my_index', using=es).search()\n",
    "q = Q('multi_match', query='Quick pets', fields=['title^2','body'],\n",
    "      tie_breaker=0.3)\n",
    "s = s.query(q)\n",
    "res = s.execute()\n",
    "for hit in res:\n",
    "    print(hit.meta.id, hit.title, ' - ', hit.body, hit.meta.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most Fields\n",
    "\n",
    "Full-text search is a battle between recall—returning all the documents that are relevant—and precision—not returning irrelevant documents. The goal is to present the user with the most relevant documents on the first page of results.\n",
    "\n",
    "To improve recall, we cast the net wide—we include not only documents that match the user’s search terms exactly, but also documents that we believe to be pertinent to the query.\n",
    "\n",
    "A common technique for fine-tuning full-text relevance is to index the same text in multiple ways, each of which provides a different relevance signal. The main field would contain terms in their broadest-matching form to match as many documents as possible. For instance, we could do the following:\n",
    "\n",
    "* Use a stemmer to index jumps, jumping, and jumped as their root form: jump. Then it doesn’t matter if the user searches for jumped; we could still match documents containing jumping.\n",
    "* Include synonyms like jump, leap, and hop.\n",
    "* Remove diacritics, or accents: for example, ésta, está, and esta would all be indexed without accents as esta.\n",
    "\n",
    "However, if we have two documents, one of which contains jumped and the other jumping, the user would probably expect the first document to rank higher, as it contains exactly what was typed in.\n",
    "\n",
    "We can achieve this by indexing the same text in other fields to provide more-precise matching. One field may contain the unstemmed version, another the original word with diacritics, and a third might use shingles to provide information about word proximity. These other fields act as signals that increase the relevance score of each matching document. The more fields that match, the better.\n",
    "\n",
    "A document is included in the results list if it matches the broad-matching main field. If it also matches the signal fields, it gets extra points and is pushed up the results list.\n",
    "\n",
    "#### Multifield Mapping\n",
    "\n",
    "Fields can be mapped to more than one type of indexing technique:\n",
    "\n",
    "Below we have `title` indexed with the `english` analyzer and the `standard` analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"settings\": { \"number_of_shards\": 1 }, \n",
    "    \"mappings\": {\n",
    "        \"my_type\": {\n",
    "            \"properties\": {\n",
    "                \"title\": { \n",
    "                    \"type\":     \"text\",\n",
    "                    \"analyzer\": \"english\",\n",
    "                    \"fields\": {\n",
    "                        \"std\":   { \n",
    "                            \"type\":     \"text\",\n",
    "                            \"analyzer\": \"standard\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "index.create_my_index(body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '2',\n",
       " '_index': 'my_index',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'my_type',\n",
       " '_version': 1,\n",
       " 'created': True,\n",
       " 'result': 'created'}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = { \"title\": \"My rabbit jumps\" }\n",
    "es.create(index='my_index', doc_type='my_type', body = body, id=1)\n",
    "body = { \"title\": \"Jumping jack rabbits\" }\n",
    "es.create(index='my_index', doc_type='my_type', body = body, id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 My rabbit jumps 0.32088596\n",
      "2 Jumping jack rabbits 0.32088596\n"
     ]
    }
   ],
   "source": [
    "s = Index('my_index', using=es).search()\n",
    "s = s.query(Q('match', title='jumping rabbits'))\n",
    "res = s.execute()\n",
    "for hit in res:\n",
    "    print(hit.meta.id, hit.title, hit.meta.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are equally scored due to stemming of the `english` stemmer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jump,rabbit\n",
      "my,rabbit,jump\n",
      "jump,jack,rabbit\n"
     ]
    }
   ],
   "source": [
    "# effect of english analyzer on our string\n",
    "titles = ['jumping rabbits', 'My rabbit jumps', 'Jumping jack rabbits']\n",
    "for title in titles:\n",
    "    analyzed_text = [x['token'] for x in es.indices.analyze\\\n",
    "                 (analyzer='english', body=title)['tokens']]\n",
    "    print(','.join(analyzed_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try the multimatch to include the other indexed field variant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Jumping jack rabbits 1.5408249\n",
      "1 My rabbit jumps 0.32088596\n"
     ]
    }
   ],
   "source": [
    "# run search again, but with most_fields setting\n",
    "s = Index('my_index', using=es).search()\n",
    "s = s.query(Q('multi_match', query='jumping rabbits',\n",
    "              type='most_fields', fields=['title','title.std']))\n",
    "res = s.execute()\n",
    "for hit in res:\n",
    "    print(hit.meta.id, hit.title, hit.meta.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document 2 now scores higher, reflecting the fact that it is very close to the search string in terms of its original (unstemmed) content.\n",
    "\n",
    "We want to combine the scores from all matching fields, so we use the `most_fields` type. This causes the `multi_match` query to wrap the two field-clauses in a `bool` query instead of a `dis_max` query.\n",
    "\n",
    "We are using the broad-matching title field to include as many documents as possible—to increase recall—but we use the title.std field as a signal to push the most relevant results to the top.\n",
    "\n",
    "We can also boost a field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Jumping jack rabbits 4.4287987\n",
      "1 My rabbit jumps 3.2088597\n"
     ]
    }
   ],
   "source": [
    "# run search again, but boost the title field ^10 \n",
    "# to make it more relatively important than title.std\n",
    "s = Index('my_index', using=es).search()\n",
    "s = s.query(Q('multi_match', query='jumping rabbits',\n",
    "              type='most_fields', fields=['title^10','title.std']))\n",
    "res = s.execute()\n",
    "for hit in res:\n",
    "    print(hit.meta.id, hit.title, hit.meta.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
