{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch: The Definitive Guide - Python\n",
    "\n",
    "Following the examples in the book, here are Python snippets that achieve the same effect.\n",
    "\n",
    "Documentation for the Python libs:\n",
    "\n",
    "Low-level API:\n",
    "\n",
    "https://elasticsearch-py.readthedocs.io/en/master/index.html\n",
    "\n",
    "Expressive DSL API (more \"Pythonic\")\n",
    "\n",
    "http://elasticsearch-dsl.readthedocs.io/en/latest/index.html\n",
    "\n",
    "Github repo for DSL API:\n",
    "\n",
    "https://github.com/elastic/elasticsearch-dsl-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 items created\n"
     ]
    }
   ],
   "source": [
    "import index\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q\n",
    "from pprint import pprint\n",
    "\n",
    "es = Elasticsearch(\n",
    "    'localhost',\n",
    "    # sniff before doing anything\n",
    "    sniff_on_start=True,\n",
    "    # refresh nodes after a node fails to respond\n",
    "    sniff_on_connection_fail=True,\n",
    "    # and also every 60 seconds\n",
    "    sniffer_timeout=60\n",
    ")\n",
    "\n",
    "r = index.populate()\n",
    "print('{} items created'.format(len(r['items'])))\n",
    "\n",
    "# Let's repopulate the index as we deleted 'gb' in earlier chapters:\n",
    "# Run the script: populate.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Typoes and Mispelings\n",
    "\n",
    "full-text search that only matches exactly will probably frustrate your users. Wouldn’t you expect a search for “quick brown fox” to match a document containing “fast brown foxes,” “Johnny Walker” to match “Johnnie Walker,” or “Arnold Shcwarzenneger” to match “Arnold Schwarzenegger”?\n",
    "\n",
    "Fuzzy matching allows for query-time matching of misspelled words, while phonetic token filters at index time can be used for sounds-like matching.\n",
    "\n",
    "#### Fuzziness\n",
    "\n",
    "Fuzzy matching treats two words that are “fuzzily” similar as if they were the same word. First, we need to define what we mean by fuzziness. It is the concept of distance - e.g. Damerau-Levenshtein distance.\n",
    "\n",
    "Damerau observed that 80% of human misspellings have an edit distance of 1. In other words, 80% of misspellings could be corrected with a single edit to the original string.\n",
    "\n",
    "Elasticsearch supports a maximum edit distance, specified with the fuzziness parameter, of 2.\n",
    "\n",
    "Of course, the impact that a single edit has on a string depends on the length of the string. Two edits to the word hat can produce mad, so allowing two edits on a string of length 3 is overkill. The fuzziness parameter can be set to AUTO, which results in the following maximum edit distances:\n",
    "\n",
    "* 0 for strings of one or two characters\n",
    "* 1 for strings of three, four, or five characters\n",
    "* 2 for strings of more than five characters\n",
    "\n",
    "Of course, you may find that an edit distance of 2 is still overkill, and returns results that don’t appear to be related. You may get better results, and better performance, with a maximum fuzziness of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = ['Surprise me!', 'That was surprising.', 'I wasn\\'t surprised.']\n",
    "for i,txt in enumerate(data):\n",
    "    body = { \"text\": \"\"}\n",
    "    body['text'] = txt\n",
    "    es.create(index='my_index', doc_type='my_type', id=i, body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 16, 'total': 16},\n",
       " 'hits': {'hits': [{'_id': '0',\n",
       "    '_index': 'my_index',\n",
       "    '_score': 0.22585157,\n",
       "    '_source': {'text': 'Surprise me!'},\n",
       "    '_type': 'my_type'},\n",
       "   {'_id': '2',\n",
       "    '_index': 'my_index',\n",
       "    '_score': 0.1898702,\n",
       "    '_source': {'text': \"I wasn't surprised.\"},\n",
       "    '_type': 'my_type'}],\n",
       "  'max_score': 0.22585157,\n",
       "  'total': 2},\n",
       " 'timed_out': False,\n",
       " 'took': 5}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = {\n",
    "  \"query\": {\n",
    "    \"fuzzy\": {\n",
    "      \"text\": \"surprize\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "es.search(body=body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fuzzy query is a term-level query, so it doesn’t do any analysis. It takes a single term and finds all terms in the term dictionary that are within the specified fuzziness. The default fuzziness is AUTO.\n",
    "\n",
    "In our example, surprize is within an edit distance of 2 from both surprise and surprised, so documents 1 and 3 match. We could reduce the matches to just surprise with the following query:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 16, 'total': 16},\n",
       " 'hits': {'hits': [{'_id': '0',\n",
       "    '_index': 'my_index',\n",
       "    '_score': 0.22585157,\n",
       "    '_source': {'text': 'Surprise me!'},\n",
       "    '_type': 'my_type'}],\n",
       "  'max_score': 0.22585157,\n",
       "  'total': 1},\n",
       " 'timed_out': False,\n",
       " 'took': 3}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = {\n",
    "  \"query\": {\n",
    "    \"fuzzy\": {\n",
    "      \"text\": {\n",
    "        \"value\": \"surprize\",\n",
    "        \"fuzziness\": 1\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "es.search(body=body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving Performance\n",
    "\n",
    "The fuzzy query works by taking the original term and building a Levenshtein automaton—like a big graph representing all the strings that are within the specified edit distance of the original string.\n",
    "\n",
    "The fuzzy query then uses the automaton to step efficiently through all of the terms in the term dictionary to see if they match. Once it has collected all of the matching terms that exist in the term dictionary, it can compute the list of matching documents.\n",
    "\n",
    "Of course, depending on the type of data stored in the index, a fuzzy query with an edit distance of 2 can match a very large number of terms and perform very badly. Two parameters can be used to limit the performance impact:\n",
    "\n",
    "##### prefix_length\n",
    "\n",
    ">The number of initial characters that will not be “fuzzified.” **Most spelling errors occur toward the end of the word, not toward the beginning.** By using a prefix_length of 3, for example, you can signficantly reduce the number of matching terms.\n",
    "\n",
    "##### max_expansions\n",
    "\n",
    ">If a fuzzy query expands to three or four fuzzy options, the new options may be meaningful. If it produces 1,000 options, they are essentially meaningless. Use max_expansions to limit the total number of options that will be produced. The fuzzy query will collect matching terms until it runs out of terms or reaches the max_expansions limit.\n",
    "\n",
    "#### Fuzzy Match Query\n",
    "\n",
    "The `match` query supports fuzzy matching out of the box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 16, 'total': 16},\n",
       " 'hits': {'hits': [{'_id': '0',\n",
       "    '_index': 'my_index',\n",
       "    '_score': 0.48396763,\n",
       "    '_source': {'text': 'Surprise me!'},\n",
       "    '_type': 'my_type'}],\n",
       "  'max_score': 0.48396763,\n",
       "  'total': 1},\n",
       " 'timed_out': False,\n",
       " 'took': 6}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body= {\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"text\": {\n",
    "        \"query\":     \"SURPRIZE ME!\",\n",
    "        \"fuzziness\": \"AUTO\",\n",
    "        \"operator\":  \"and\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "es.search(body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 16, 'total': 16},\n",
       " 'hits': {'hits': [{'_id': '0',\n",
       "    '_index': 'my_index',\n",
       "    '_score': 0.48396763,\n",
       "    '_source': {'text': 'Surprise me!'},\n",
       "    '_type': 'my_type'},\n",
       "   {'_id': '2',\n",
       "    '_index': 'my_index',\n",
       "    '_score': 0.1898702,\n",
       "    '_source': {'text': \"I wasn't surprised.\"},\n",
       "    '_type': 'my_type'}],\n",
       "  'max_score': 0.48396763,\n",
       "  'total': 2},\n",
       " 'timed_out': False,\n",
       " 'took': 7}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = {\n",
    "  \"query\": {\n",
    "    \"multi_match\": {\n",
    "      \"fields\":  [ \"text\", \"title\" ],\n",
    "      \"query\":     \"SURPRIZE ME!\",\n",
    "      \"fuzziness\": \"AUTO\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "es.search(body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's add some more data to test how fuzziness relates to relevance:\n",
    "data = ['The element of surprize!', 'That is surprising.', 'Inside every Kinder egg is a surprise.']\n",
    "for i,txt in enumerate(data):\n",
    "    body = { \"text\": \"\"}\n",
    "    body['text'] = txt\n",
    "    es.create(index='my_index', doc_type='my_type', id=i+3, body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 16, 'total': 16},\n",
       " 'hits': {'hits': [{'_id': '2',\n",
       "    '_index': 'my_index',\n",
       "    '_score': 0.45747715,\n",
       "    '_source': {'text': \"I wasn't surprised.\"},\n",
       "    '_type': 'my_type'},\n",
       "   {'_id': '3',\n",
       "    '_index': 'my_index',\n",
       "    '_score': 0.2876821,\n",
       "    '_source': {'text': 'The element of surprize!'},\n",
       "    '_type': 'my_type'},\n",
       "   {'_id': '5',\n",
       "    '_index': 'my_index',\n",
       "    '_score': 0.2500978,\n",
       "    '_source': {'text': 'Inside every Kinder egg is a surprise.'},\n",
       "    '_type': 'my_type'},\n",
       "   {'_id': '0',\n",
       "    '_index': 'my_index',\n",
       "    '_score': 0.22585157,\n",
       "    '_source': {'text': 'Surprise me!'},\n",
       "    '_type': 'my_type'}],\n",
       "  'max_score': 0.45747715,\n",
       "  'total': 4},\n",
       " 'timed_out': False,\n",
       " 'took': 8}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body= {\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"text\": {\n",
    "        \"query\":     \"SURPRIZE!\",\n",
    "        \"fuzziness\": \"AUTO\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "es.search(body=body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring Fuzziness\n",
    "\n",
    "Imagine that we have 1,000 documents containing “Schwarzenegger,” and just one document with the misspelling “Schwarzeneger.” According to the theory of term frequency/inverse document frequency, the misspelling is much more relevant than the correct spelling, because it appears in far fewer documents!\n",
    "\n",
    "\n",
    "Fuzzy queries alone are much less useful than they initially appear. They are better used as part of a “bigger” feature, such as the search-as-you-type completion suggester or the did-you-mean phrase suggester.\n",
    "\n",
    "#### Phonetic Matching\n",
    "\n",
    "It might be useful to match by phonetic similarity - words that sound similar (despite different spellings):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"dbl_metaphone\": { \n",
    "          \"type\":    \"phonetic\",\n",
    "          \"encoder\": \"double_metaphone\"\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"dbl_metaphone\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\":    \"dbl_metaphone\" \n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This won't work as it needs a plug-in for [Phoentic analysis](\n",
    "https://www.elastic.co/guide/en/elasticsearch/plugins/5.2/analysis-phonetic.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
