{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch: The Definitive Guide - Python\n",
    "\n",
    "Following the examples in the book, here are Python snippets that achieve the same effect.\n",
    "\n",
    "Documentation for the Python libs:\n",
    "\n",
    "Low-level API:\n",
    "\n",
    "https://elasticsearch-py.readthedocs.io/en/master/index.html\n",
    "\n",
    "Expressive DSL API (more \"Pythonic\")\n",
    "\n",
    "http://elasticsearch-dsl.readthedocs.io/en/latest/index.html\n",
    "\n",
    "Github repo for DSL API:\n",
    "\n",
    "https://github.com/elastic/elasticsearch-dsl-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 items created\n"
     ]
    }
   ],
   "source": [
    "import index\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q\n",
    "from pprint import pprint\n",
    "\n",
    "es = Elasticsearch(\n",
    "    'localhost',\n",
    "    # sniff before doing anything\n",
    "    sniff_on_start=True,\n",
    "    # refresh nodes after a node fails to respond\n",
    "    sniff_on_connection_fail=True,\n",
    "    # and also every 60 seconds\n",
    "    sniffer_timeout=60\n",
    ")\n",
    "\n",
    "r = index.populate()\n",
    "print('{} items created'.format(len(r['items'])))\n",
    "\n",
    "# Let's repopulate the index as we deleted 'gb' in earlier chapters:\n",
    "# Run the script: populate.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Synonyms\n",
    "\n",
    "#### Expand or contract\n",
    "\n",
    "It is possible to replace synonyms by simple expansion, simple contraction, or generic expansion. We will look at the trade-offs of each of these techniques in this section.\n",
    "\n",
    "#### Simple expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"my_synonym_filter\": {\n",
    "          \"type\": \"synonym\", \n",
    "          \"synonyms\": [ \n",
    "            \"jump,hop,leap\"\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_synonyms\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"my_synonym_filter\" \n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos 0: (the)\n",
      "Pos 1: (cow)\n",
      "Pos 2: (did)\n",
      "Pos 3: (not)\n",
      "Pos 4: (jump)\n",
      "Pos 4: (hop)\n",
      "Pos 4: (leap)\n",
      "Pos 5: (over)\n",
      "Pos 6: (the)\n",
      "Pos 7: (moon)\n"
     ]
    }
   ],
   "source": [
    "# test with my_synonyms\n",
    "text = \"the cow did not jump over the moon\" \n",
    "analyzed_text = [[x['position'],x['token']] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_synonyms', text=text)['tokens']]\n",
    "for item in analyzed_text:\n",
    "    print('Pos {}: ({})'.format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![screenshot 2017-03-13 11 59 34](https://cloud.githubusercontent.com/assets/28526/23870720/a15f6eac-07e4-11e7-8cfd-9099e087fd12.png)\n",
    "\n",
    "#### Simple contraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"my_synonym_filter\": {\n",
    "          \"type\": \"synonym\", \n",
    "          \"synonyms\": [ \n",
    "            \"leap,hop => jump\"\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_synonyms\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"my_synonym_filter\" \n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "    \"mappings\": {\n",
    "    \"test\": {\n",
    "      \"properties\": {\n",
    "        \"text\": {\n",
    "          \"type\":  \"text\",\n",
    "          \"analyzer\": \"my_synonyms\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos 0: (the)\n",
      "Pos 1: (cow)\n",
      "Pos 2: (did)\n",
      "Pos 3: (not)\n",
      "Pos 4: (jump)\n",
      "Pos 5: (over)\n",
      "Pos 6: (the)\n",
      "Pos 7: (moon)\n"
     ]
    }
   ],
   "source": [
    "# test with my_synonyms\n",
    "text = \"the cow did not leap over the moon\" \n",
    "analyzed_text = [[x['position'],x['token']] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_synonyms', text=text)['tokens']]\n",
    "for item in analyzed_text:\n",
    "    print('Pos {}: ({})'.format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It must be applied both at index time and at query time, to ensure that query terms are mapped to the same single value that exists in the index. Let's demonstrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '1',\n",
       " '_index': 'my_index',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'test',\n",
       " '_version': 1,\n",
       " 'created': True,\n",
       " 'result': 'created'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"the cow did not leap over the moon\" \n",
    "body = { \"text\": text }\n",
    "es.create(index='my_index', doc_type='test', body=body, id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/1): {'text': 'the cow did not leap over the moon'}>]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for hop \n",
    "s = Search(using=es)\n",
    "s = s.query('match', text='hop')\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screenshot 2017-03-13 12 25 10](https://cloud.githubusercontent.com/assets/28526/23871542/1d4c8556-07e8-11e7-8e47-c65a8eba39fa.png)\n",
    "\n",
    "#### Genre Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"my_synonym_filter\": {\n",
    "          \"type\": \"synonym\", \n",
    "          \"synonyms\": [ \n",
    "            \"cat    => cat,pet\",\n",
    "            \"kitten => kitten,cat,pet\",\n",
    "            \"dog    => dog,pet\",\n",
    "            \"puppy  => puppy,dog,pet\"\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_synonyms\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"my_synonym_filter\" \n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "    \"mappings\": {\n",
    "    \"test\": {\n",
    "      \"properties\": {\n",
    "        \"text\": {\n",
    "          \"type\":  \"text\",\n",
    "          \"analyzer\": \"my_synonyms\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos 0: (i)\n",
      "Pos 1: (am)\n",
      "Pos 2: (looking)\n",
      "Pos 3: (for)\n",
      "Pos 4: (a)\n",
      "Pos 5: (kitten)\n",
      "Pos 5: (cat)\n",
      "Pos 5: (pet)\n"
     ]
    }
   ],
   "source": [
    "# test with my_synonyms for kittens\n",
    "text = \"i am looking for a kitten\" \n",
    "analyzed_text = [[x['position'],x['token']] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_synonyms', text=text)['tokens']]\n",
    "for item in analyzed_text:\n",
    "    print('Pos {}: ({})'.format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos 0: (i)\n",
      "Pos 1: (am)\n",
      "Pos 2: (looking)\n",
      "Pos 3: (for)\n",
      "Pos 4: (a)\n",
      "Pos 5: (pet)\n"
     ]
    }
   ],
   "source": [
    "# But what about pets?\n",
    "text = \"i am looking for a pet\" \n",
    "analyzed_text = [[x['position'],x['token']] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_synonyms', text=text)['tokens']]\n",
    "for item in analyzed_text:\n",
    "    print('Pos {}: ({})'.format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no mapping for pet here, but that would be catered for in an indexed doc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '3',\n",
       " '_index': 'my_index',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'test',\n",
       " '_version': 1,\n",
       " 'created': True,\n",
       " 'result': 'created'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"who wants a dog?\" \n",
    "body = { \"text\": text }\n",
    "es.create(index='my_index', doc_type='test', body=body, id=1)\n",
    "text = \"who wants a cat?\" \n",
    "body = { \"text\": text }\n",
    "es.create(index='my_index', doc_type='test', body=body, id=2)\n",
    "text = \"who wants a kitten?\" \n",
    "body = { \"text\": text }\n",
    "es.create(index='my_index', doc_type='test', body=body, id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/3): {'text': 'who wants a kitten?'}>, <Hit(my_index/test/2): {'text': 'who wants a cat?'}>, <Hit(my_index/test/1): {'text': 'who wants a dog?'}>]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for a pet - ahhh, how cute!\n",
    "s = Search(using=es)\n",
    "s = s.query('match', text='can i find a pet?')\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also have the best of both worlds by applying expansion at index time to ensure that the genres are present in the index. Then, at query time, you can choose to not apply synonyms (so that a query for kitten returns only documents about kittens) or to apply synonyms in order to match kittens, cats and pets (including the canine variety).\n",
    "\n",
    "With the preceding example rules above, the IDF for kitten will be correct, while the IDF for cat and pet will be artificially deflated. However, this works in your favor—a genre-expanded query for kitten OR cat OR pet will rank documents with kitten highest, followed by documents with cat, and documents with pet would be right at the bottom.\n",
    "\n",
    "#### Synonyms and The Analysis Chain\n",
    "\n",
    "Imagine that we have an analyzer that consists of the standard tokenizer, with the lowercase token filter followed by a synonym token filter. The analysis process for the text U.S.A. would look like this:\n",
    "\n",
    "`\n",
    "original string                  → \"U.S.A.\"\n",
    "standard           tokenizer     → (U),(S),(A)\n",
    "lowercase          token filter  → (u),(s),(a)\n",
    "synonym            token filter  → (usa)\n",
    "`\n",
    "\n",
    "If we had specified the synonym as U.S.A., it would never match anything because, by the time my_synonym_filter sees the terms, the periods have been removed and the letters have been lowercased.\n",
    "\n",
    "This is an important point to consider. What if we want to combine synonyms with stemming, so that jumps, jumped, jump, leaps, leaped, and leap are all indexed as the single term jump? We could place the synonyms filter before the stemmer and list all inflections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '1',\n",
       " '_index': 'my_index',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'test',\n",
       " '_version': 1,\n",
       " 'created': True,\n",
       " 'result': 'created'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first without any stemmer - let's see what happens:\n",
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"my_synonym_filter\": {\n",
    "          \"type\": \"synonym\", \n",
    "          \"synonyms\": [ \n",
    "            \"jumps,jumped,leap,leaps,leaped => jump\"\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_synonyms\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"my_synonym_filter\" \n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "    \"mappings\": {\n",
    "    \"test\": {\n",
    "      \"properties\": {\n",
    "        \"text\": {\n",
    "          \"type\":  \"text\",\n",
    "          \"analyzer\": \"my_synonyms\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)\n",
    "text = \"the cow jumped over the moon\" \n",
    "body = { \"text\": text }\n",
    "es.create(index='my_index', doc_type='test', body=body, id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: []>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for a cow that jumps\n",
    "s = Search(using=es)\n",
    "q = Q('match', text='cow') & Q('match', text='jumps')\n",
    "s = s.query(q)\n",
    "s.execute()\n",
    "# it should work because we \"stemmed\" all terms via our synonyms contraction to jump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now consider an alternative strategy to use a stemmer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now with a stemmer\n",
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"my_synonym_filter\": {\n",
    "          \"type\": \"synonym\", \n",
    "          \"synonyms\": [ \n",
    "            \"leap => jump\"\n",
    "          ]\n",
    "        },\n",
    "        \"my_stemmer\": {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"english\" \n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_synonyms\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"my_stemmer\",\n",
    "            \"my_synonym_filter\" \n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "    \"mappings\": {\n",
    "    \"test\": {\n",
    "      \"properties\": {\n",
    "        \"text\": {\n",
    "          \"type\":  \"text\",\n",
    "          \"analyzer\": \"my_synonyms\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '1',\n",
       " '_index': 'my_index',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'test',\n",
       " '_version': 1,\n",
       " 'created': True,\n",
       " 'result': 'created'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"the cow jumped over the moon\" \n",
    "body = { \"text\": text }\n",
    "es.create(index='my_index', doc_type='test', body=body, id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/1): {'text': 'the cow jumped over the moon'}>]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for a cow that jumps\n",
    "s = Search(using=es)\n",
    "q = Q('match', text='jumps')\n",
    "s = s.query(q)\n",
    "s.execute()\n",
    "# it should work because we \"stemmed\" all terms via our synonyms contraction to jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/1): {'text': 'the cow jumped over the moon'}>]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But does it catch all those terms: jumps,jumped,leap,leaps,leaped and jumping?\n",
    "# search for a cow that jumps\n",
    "s = Search(using=es)\n",
    "q = Q('match', text='jumps') & Q('match', text='leap') & Q('match', text='leaps') & \\\n",
    "    Q('match', text='leaped') & Q('match', text='jumping')\n",
    "s = s.query(q)\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case-Sensitive Synonyms\n",
    "\n",
    "Synonym filters usually placed after lowercase filters. But what if we really want to check for `CAT scan` and not cats?\n",
    "\n",
    "Solution: create two synonym filters:\n",
    "\n",
    "##### Case-sensitive rules:\n",
    "\n",
    "`\"CAT,CAT scan           => cat_scan\"\n",
    "\"PET,PET scan           => pet_scan\"\n",
    "\"Johnny Little,J Little => johnny_little\"\n",
    "\"Johnny Small,J Small   => johnny_small\"\n",
    "`\n",
    "\n",
    "##### Case-insensitive rules:\n",
    "\n",
    "`\n",
    "\"cat                    => cat,pet\"\n",
    "\"dog                    => dog,pet\"\n",
    "\"cat scan,cat_scan scan => cat_scan\"\n",
    "\"pet scan,pet_scan scan => pet_scan\"\n",
    "\"little,small\"\n",
    "`\n",
    "\n",
    "Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# two sets of synonyms without a stemmer here:\n",
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"my_syns_1\": {\n",
    "          \"type\": \"synonym\", \n",
    "          \"synonyms\": [ \n",
    "            \"CAT,CAT scan           => cat_scan\",\n",
    "            \"PET,PET scan           => pet_scan\",\n",
    "            \"Johnny Little,J Little => johnny_little\",\n",
    "            \"Johnny Small,J Small   => johnny_small\"\n",
    "          ]\n",
    "        },\n",
    "        \"my_syns_2\": {\n",
    "          \"type\": \"synonym\", \n",
    "          \"synonyms\": [ \n",
    "            \"cat                    => cat,pet\",\n",
    "            \"dog                    => dog,pet\",\n",
    "            \"cat scan,cat_scan scan => cat_scan\",\n",
    "            \"pet scan,pet_scan scan => pet_scan\",\n",
    "            \"little,small\"\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_synonyms\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"my_syns_1\",\n",
    "            \"my_syns_2\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "    \"mappings\": {\n",
    "    \"test\": {\n",
    "      \"properties\": {\n",
    "        \"text\": {\n",
    "          \"type\":  \"text\",\n",
    "          \"analyzer\": \"my_synonyms\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)\n",
    "text = \"the man went to get a cat\" \n",
    "body = { \"text\": text }\n",
    "r = es.create(index='my_index', doc_type='test', body=body, id=1)\n",
    "text = \"the man went to get a CAT scan\" \n",
    "body = { \"text\": text }\n",
    "r = es.create(index='my_index', doc_type='test', body=body, id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/1): {'text': 'the man went to get a cat'}>]>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for a man with a cat\n",
    "s = Search(using=es)\n",
    "q = Q('match', text='cat')\n",
    "s = s.query(q)\n",
    "s.execute()\n",
    "# it should work because we \"stemmed\" all terms via our synonyms contraction to jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/2): {'text': 'the man went to get a CAT scan'}>]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for a man with a cat\n",
    "s = Search(using=es)\n",
    "q = Q('match', text='CAT')\n",
    "s = s.query(q)\n",
    "s.execute()\n",
    "# it should work because we \"stemmed\" all terms via our synonyms contraction to jump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiword Synonyms and Phrase Queries\n",
    "\n",
    "So far, synonyms appear to be quite straightforward. Unfortunately, this is where things start to go wrong. For phrase queries to function correctly, Elasticsearch needs to know the position that each term occupies in the original text. Multiword synonyms can play havoc with term positions, especially when the injected synonyms are of differing lengths.\n",
    "\n",
    "To demonstrate, we’ll create a synonym token filter that uses this rule:\n",
    "\n",
    "`\"usa,united states,u s a,united states of america\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"my_synonym_filter\": {\n",
    "          \"type\": \"synonym\",\n",
    "          \"synonyms\": [\n",
    "            \"usa,united states,u s a,united states of america\"\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_synonyms\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"my_synonym_filter\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos 0: (the)\n",
      "Pos 1: (united)\n",
      "Pos 1: (usa)\n",
      "Pos 1: (u)\n",
      "Pos 1: (united)\n",
      "Pos 2: (states)\n",
      "Pos 2: (s)\n",
      "Pos 2: (states)\n",
      "Pos 3: (is)\n",
      "Pos 3: (a)\n",
      "Pos 3: (of)\n",
      "Pos 4: (wealthy)\n",
      "Pos 4: (america)\n"
     ]
    }
   ],
   "source": [
    "# test with my_synonyms \n",
    "text = \"The United States is wealthy\" \n",
    "analyzed_text = [[x['position'],x['token']] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_synonyms', text=text)['tokens']]\n",
    "for item in analyzed_text:\n",
    "    print('Pos {}: ({})'.format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 1, 'total': 1},\n",
       " 'explanations': [{'explanation': 'text:\"(usa united u united) (is states s states) (wealthy a of) america\"',\n",
       "   'index': 'my_index',\n",
       "   'valid': True}],\n",
       " 'valid': True}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at this query validation:\n",
    "body = {\n",
    "  \"query\": {\n",
    "    \"match_phrase\": {\n",
    "      \"text\": {\n",
    "        \"query\": \"usa is wealthy\",\n",
    "        \"analyzer\": \"my_synonyms\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "es.indices.validate_query(index='my_index', body=body, explain=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any combination of the explained text would work for this query:\n",
    "\n",
    "`(usa united u united) (is states s states) (wealthy a of) america`\n",
    "\n",
    "* `usa is wealthy america`\n",
    "* `u is of america`\n",
    "* `usa states of america`\n",
    "\n",
    "What a mess!\n",
    "\n",
    "The way to avoid it is to use simple contract where possible to inject a single term that represents all synonyms and to use the same synonym token filter at query time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"my_synonym_filter\": {\n",
    "          \"type\": \"synonym\",\n",
    "          \"synonyms\": [\n",
    "            \"united states,u s a,united states of america=>usa\"\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_synonyms\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"my_synonym_filter\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos 0: (the)\n",
      "Pos 1: (usa)\n",
      "Pos 2: (is)\n",
      "Pos 3: (wealthy)\n"
     ]
    }
   ],
   "source": [
    "# test it now\n",
    "text = \"The United States is wealthy\" \n",
    "analyzed_text = [[x['position'],x['token']] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_synonyms', text=text)['tokens']]\n",
    "for item in analyzed_text:\n",
    "    print('Pos {}: ({})'.format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 1, 'total': 1},\n",
       " 'explanations': [{'explanation': 'text:\"usa is wealthy\"',\n",
       "   'index': 'my_index',\n",
       "   'valid': True}],\n",
       " 'valid': True}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now validate the query again:\n",
    "body = {\n",
    "  \"query\": {\n",
    "    \"match_phrase\": {\n",
    "      \"text\": {\n",
    "        \"query\": \"usa is wealthy\",\n",
    "        \"analyzer\": \"my_synonyms\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "es.indices.validate_query(index='my_index', body=body, explain=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Symbol Synonyms\n",
    "\n",
    "I am thrilled to be at work on Sunday.\n",
    "I am thrilled to be at work on Sunday :(\n",
    "\n",
    "The second string would have the emoticon stripped out.\n",
    "\n",
    "If we want to handle emoticons, then create a mapping character filter:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"char_filter\": {\n",
    "        \"emoticons\": {\n",
    "          \"type\": \"mapping\",\n",
    "          \"mappings\": [ \n",
    "            \":)=>emoticon_happy\",\n",
    "            \":(=>emoticon_sad\"\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_emoticons\": {\n",
    "          \"char_filter\": \"emoticons\",\n",
    "          \"tokenizer\":   \"standard\",\n",
    "          \"filter\":    [ \"lowercase\" ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos 0: (i)\n",
      "Pos 1: (am)\n",
      "Pos 2: (emoticon_happy)\n",
      "Pos 3: (not)\n",
      "Pos 4: (emoticon_sad)\n"
     ]
    }
   ],
   "source": [
    "# test with my_synonyms - let's see what the analyzer does with our => mappings:\n",
    "text = \"I am :) not :(\" \n",
    "analyzed_text = [[x['position'],x['token']] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_emoticons', text=text)['tokens']]\n",
    "for item in analyzed_text:\n",
    "    print('Pos {}: ({})'.format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is unlikely that anybody would ever search for emoticon_happy, but ensuring that important symbols like emoticons are included in the index can be helpful when doing sentiment analysis. Of course, we could equally have used real words, like happy and sad.\n",
    "\n",
    "#### Updating Synonyms\n",
    "\n",
    "Finally, we can update synonyms for a filter by using a synonyms file that must be present on every node in the cluster. \n",
    "\n",
    "The path to the synonyms file should be specified with the `synonyms_path` parameter, and should be either absolute or relative to the Elasticsearch config directory. See [Updating Stopwords](https://www.elastic.co/guide/en/elasticsearch/guide/master/using-stopwords.html#updating-stopwords) for techniques that can be used to refresh the synonyms list.\n",
    "\n",
    "Synonyms text uses same synonyms syntax for expansions and contractions. Let's assume the following data in the synonyms.txt file:\n",
    "\n",
    "`\n",
    "manager => leader,boss,person\n",
    "chef => chef,cook,person\n",
    "maid => maid,housemaid,young_lady,female,person\n",
    "woman => woman, female, girl, feminine\n",
    "`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"my_synonym_filter\": {\n",
    "          \"type\": \"synonym\", \n",
    "          \"synonyms_path\": \"analysis/synonyms.txt\"\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_synonyms\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"my_synonym_filter\" \n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "    \"mappings\": {\n",
    "    \"test\": {\n",
    "      \"properties\": {\n",
    "        \"text\": {\n",
    "          \"type\":  \"text\",\n",
    "          \"analyzer\": \"my_synonyms\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)\n",
    "# Need to add the synonyms.txt file else will throw RequestError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos 0: (the)\n",
      "Pos 1: (chef)\n",
      "Pos 1: (cook)\n",
      "Pos 1: (person)\n",
      "Pos 2: (is)\n",
      "Pos 3: (the)\n",
      "Pos 4: (leader)\n",
      "Pos 4: (boss)\n",
      "Pos 4: (person)\n",
      "Pos 5: (of)\n",
      "Pos 6: (the)\n",
      "Pos 7: (maid)\n",
      "Pos 7: (housemaid)\n",
      "Pos 7: (young_lady)\n",
      "Pos 7: (female)\n",
      "Pos 7: (person)\n"
     ]
    }
   ],
   "source": [
    "# test with my_synonyms analyzer\n",
    "text = \"The chef is the manager of the maid\" \n",
    "analyzed_text = [[x['position'],x['token']] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_synonyms', text=text)['tokens']]\n",
    "for item in analyzed_text:\n",
    "    print('Pos {}: ({})'.format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 1, 'total': 1},\n",
       " 'explanations': [{'explanation': 'text:\"the (chef cook person) loves the (maid housemaid young_lady female person)\"',\n",
       "   'index': 'my_index',\n",
       "   'valid': True}],\n",
       " 'valid': True}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now validate a query :\n",
    "body = {\n",
    "  \"query\": {\n",
    "    \"match_phrase\": {\n",
    "      \"text\": {\n",
    "        \"query\": \"the chef loves the maid\",\n",
    "        \"analyzer\": \"my_synonyms\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "es.indices.validate_query(index='my_index', body=body, explain=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '1',\n",
       " '_index': 'my_index',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'test',\n",
       " '_version': 1,\n",
       " 'created': True,\n",
       " 'result': 'created'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's store a doc:\n",
    "text = \"the chef is often the manager of the maid\" \n",
    "body = { \"text\": text }\n",
    "es.create(index='my_index', doc_type='test', body=body, id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: []>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Search(using=es)\n",
    "q = Q('match', text='girl')\n",
    "s = s.query(q)\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 5, 'total': 5},\n",
       " 'hits': {'hits': [], 'max_score': None, 'total': 0},\n",
       " 'timed_out': False,\n",
       " 'took': 1}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Girl did not work, so let's try query-side analysis too:\n",
    "body = {\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"text\": {\n",
    "        \"query\": \"girl\",\n",
    "        \"analyzer\": \"my_synonyms\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "es.search(index='my_index', body=body, explain=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change `synonyms.text` to:\n",
    "\n",
    "`\n",
    "manager => leader,boss,person\n",
    "chef => chef,cook,person\n",
    "maid => maid,housemaid,young_lady,female,person\n",
    "woman, female, girl, feminine => female\n",
    "`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '1',\n",
       " '_index': 'my_index',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'test',\n",
       " '_version': 1,\n",
       " 'created': True,\n",
       " 'result': 'created'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"my_synonym_filter\": {\n",
    "          \"type\": \"synonym\", \n",
    "          \"synonyms_path\": \"analysis/synonyms.txt\"\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_synonyms\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"my_synonym_filter\" \n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "    \"mappings\": {\n",
    "    \"test\": {\n",
    "      \"properties\": {\n",
    "        \"text\": {\n",
    "          \"type\":  \"text\",\n",
    "          \"analyzer\": \"my_synonyms\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)\n",
    "# Need to add the synonyms.txt file else will throw RequestError\n",
    "# Let's store a doc again to make sure it's indexed:\n",
    "text = \"the chef is often the manager of the maid\" \n",
    "body = { \"text\": text }\n",
    "es.create(index='my_index', doc_type='test', body=body, id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/1): {'text': 'the chef is often the manager of the maid'}>]>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's try girl again:\n",
    "s = Search(using=es)\n",
    "q = Q('match', text='girl')\n",
    "s = s.query(q)\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's going on?\n",
    "`\n",
    "maid => maid,housemaid,young_lady,female,person\n",
    "woman, female, girl, feminine => female\n",
    "`\n",
    "\n",
    "Any doc that we want to search using any of the female synonyms needs to make sure that the universal synonym (in this case 'female') is used at index time:\n",
    "\n",
    "`\"The chef is often the manager of the maid\"` \n",
    "`\n",
    "Pos 0: (the)\n",
    "Pos 1: (chef)\n",
    "Pos 1: (cook)\n",
    "Pos 1: (person)\n",
    "Pos 2: (is)\n",
    "Pos 3: (often)\n",
    "Pos 4: (the)\n",
    "Pos 5: (leader)\n",
    "Pos 5: (boss)\n",
    "Pos 5: (person)\n",
    "Pos 6: (of)\n",
    "Pos 7: (the)\n",
    "Pos 8: (maid)\n",
    "Pos 8: (housemaid)\n",
    "Pos 8: (young_lady)\n",
    "Pos 8: (female)\n",
    "Pos 8: (person)`\n",
    "\n",
    "So at position 8, our index will store `female` as one of the synonyms.\n",
    "\n",
    "After that, we need to ensure that any female related synonym is mapped to female:\n",
    "\n",
    "`woman, female, girl, feminine => female`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '2',\n",
       " '_index': 'my_index',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'test',\n",
       " '_version': 1,\n",
       " 'created': True,\n",
       " 'result': 'created'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's add another example:\n",
    "text = \"the cook is often the boss of the maid\" \n",
    "body = { \"text\": text }\n",
    "es.create(index='my_index', doc_type='test', body=body, id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the chef is often the manager of the maid 0.54167056\n",
      "the cook is often the boss of the maid 0.42068246\n"
     ]
    }
   ],
   "source": [
    "# Now let's try chef:\n",
    "s = Search(using=es)\n",
    "q = Q('match', text='chef')\n",
    "s = s.query(q)\n",
    "res = s.execute()\n",
    "for hit in res:\n",
    "    print(hit.text, hit.meta.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the chef is often the manager of the maid 0.3435723\n",
      "the cook is often the boss of the maid 0.31504473\n"
     ]
    }
   ],
   "source": [
    "# Now let's try chef:\n",
    "s = Search(using=es)\n",
    "q = Q('match', text='cook')\n",
    "s = s.query(q)\n",
    "res = s.execute()\n",
    "for hit in res:\n",
    "    print(hit.text, hit.meta.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 5, 'total': 5},\n",
       " 'hits': {'hits': [{'_explanation': {'description': 'weight(text:cook in 0) [PerFieldSimilarity], result of:',\n",
       "     'details': [{'description': 'score(doc=0,freq=1.0 = termFreq=1.0\\n), product of:',\n",
       "       'details': [{'description': 'idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:',\n",
       "         'details': [{'description': 'docFreq', 'details': [], 'value': 1.0},\n",
       "          {'description': 'docCount', 'details': [], 'value': 1.0}],\n",
       "         'value': 0.2876821},\n",
       "        {'description': 'tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:',\n",
       "         'details': [{'description': 'termFreq=1.0',\n",
       "           'details': [],\n",
       "           'value': 1.0},\n",
       "          {'description': 'parameter k1', 'details': [], 'value': 1.2},\n",
       "          {'description': 'parameter b', 'details': [], 'value': 0.75},\n",
       "          {'description': 'avgFieldLength', 'details': [], 'value': 17.0},\n",
       "          {'description': 'fieldLength', 'details': [], 'value': 10.24}],\n",
       "         'value': 1.1942776}],\n",
       "       'value': 0.3435723}],\n",
       "     'value': 0.3435723},\n",
       "    '_id': '1',\n",
       "    '_index': 'my_index',\n",
       "    '_node': 'nKjjkxx5SfWhB1vabVu5ig',\n",
       "    '_score': 0.3435723,\n",
       "    '_shard': '[my_index][3]',\n",
       "    '_source': {'text': 'the chef is often the manager of the maid'},\n",
       "    '_type': 'test'},\n",
       "   {'_explanation': {'description': 'weight(text:cook in 0) [PerFieldSimilarity], result of:',\n",
       "     'details': [{'description': 'score(doc=0,freq=1.0 = termFreq=1.0\\n), product of:',\n",
       "       'details': [{'description': 'idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:',\n",
       "         'details': [{'description': 'docFreq', 'details': [], 'value': 1.0},\n",
       "          {'description': 'docCount', 'details': [], 'value': 1.0}],\n",
       "         'value': 0.2876821},\n",
       "        {'description': 'tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:',\n",
       "         'details': [{'description': 'termFreq=1.0',\n",
       "           'details': [],\n",
       "           'value': 1.0},\n",
       "          {'description': 'parameter k1', 'details': [], 'value': 1.2},\n",
       "          {'description': 'parameter b', 'details': [], 'value': 0.75},\n",
       "          {'description': 'avgFieldLength', 'details': [], 'value': 13.0},\n",
       "          {'description': 'fieldLength', 'details': [], 'value': 10.24}],\n",
       "         'value': 1.0951141}],\n",
       "       'value': 0.3150447}],\n",
       "     'value': 0.3150447},\n",
       "    '_id': '2',\n",
       "    '_index': 'my_index',\n",
       "    '_node': 'nKjjkxx5SfWhB1vabVu5ig',\n",
       "    '_score': 0.31504473,\n",
       "    '_shard': '[my_index][2]',\n",
       "    '_source': {'text': 'the cook is often the boss of the maid'},\n",
       "    '_type': 'test'}],\n",
       "  'max_score': 0.3435723,\n",
       "  'total': 2},\n",
       " 'timed_out': False,\n",
       " 'took': 1}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now validate a query :\n",
    "body = {\n",
    "  \"query\": {\n",
    "    \"match_phrase\": {\n",
    "      \"text\": {\n",
    "        \"query\": \"cook\",\n",
    "        \"analyzer\": \"my_synonyms\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "es.search(index='my_index', body=body, explain=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:17\n",
      "Pos 0: (the)\n",
      "Pos 1: (chef)\n",
      "Pos 1: (cook)\n",
      "Pos 1: (person)\n",
      "Pos 2: (is)\n",
      "Pos 3: (often)\n",
      "Pos 4: (the)\n",
      "Pos 5: (leader)\n",
      "Pos 5: (boss)\n",
      "Pos 5: (person)\n",
      "Pos 6: (of)\n",
      "Pos 7: (the)\n",
      "Pos 8: (maid)\n",
      "Pos 8: (housemaid)\n",
      "Pos 8: (young_lady)\n",
      "Pos 8: (female)\n",
      "Pos 8: (person)\n"
     ]
    }
   ],
   "source": [
    "# Let's compare the expansions:\n",
    "# test with my_synonyms analyzer\n",
    "text = \"the chef is often the manager of the maid\" \n",
    "analyzed_text = [[x['position'],x['token']] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_synonyms', text=text)['tokens']]\n",
    "print('Number of tokens:{}'.format(len(analyzed_text)))\n",
    "for item in analyzed_text:\n",
    "    print('Pos {}: ({})'.format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:13\n",
      "Pos 0: (the)\n",
      "Pos 1: (cook)\n",
      "Pos 2: (is)\n",
      "Pos 3: (often)\n",
      "Pos 4: (the)\n",
      "Pos 5: (boss)\n",
      "Pos 6: (of)\n",
      "Pos 7: (the)\n",
      "Pos 8: (maid)\n",
      "Pos 8: (housemaid)\n",
      "Pos 8: (young_lady)\n",
      "Pos 8: (female)\n",
      "Pos 8: (person)\n"
     ]
    }
   ],
   "source": [
    "# Let's compare the expansions:\n",
    "# test with my_synonyms analyzer\n",
    "text = \"the cook is often the boss of the maid\" \n",
    "analyzed_text = [[x['position'],x['token']] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_synonyms', text=text)['tokens']]\n",
    "print('Number of tokens:{}'.format(len(analyzed_text)))\n",
    "for item in analyzed_text:\n",
    "    print('Pos {}: ({})'.format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tfNorm = (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)`\n",
    "\n",
    "This equation is part of the relevancy score and is proportional to avgFieldLength, which is greated for the first answer, hence the score.\n",
    "\n",
    "We can try adding more data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '3',\n",
       " '_index': 'my_index',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'test',\n",
       " '_version': 1,\n",
       " 'created': True,\n",
       " 'result': 'created'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's add another example:\n",
    "text = \"the cook is often the boss of the maid and anyone else who hangs in the kitchen.\" \n",
    "body = { \"text\": text }\n",
    "es.create(index='my_index', doc_type='test', body=body, id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 5, 'total': 5},\n",
       " 'hits': {'hits': [{'_explanation': {'description': 'weight(text:cook in 0) [PerFieldSimilarity], result of:',\n",
       "     'details': [{'description': 'score(doc=0,freq=1.0 = termFreq=1.0\\n), product of:',\n",
       "       'details': [{'description': 'idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:',\n",
       "         'details': [{'description': 'docFreq', 'details': [], 'value': 1.0},\n",
       "          {'description': 'docCount', 'details': [], 'value': 1.0}],\n",
       "         'value': 0.2876821},\n",
       "        {'description': 'tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:',\n",
       "         'details': [{'description': 'termFreq=1.0',\n",
       "           'details': [],\n",
       "           'value': 1.0},\n",
       "          {'description': 'parameter k1', 'details': [], 'value': 1.2},\n",
       "          {'description': 'parameter b', 'details': [], 'value': 0.75},\n",
       "          {'description': 'avgFieldLength', 'details': [], 'value': 17.0},\n",
       "          {'description': 'fieldLength', 'details': [], 'value': 10.24}],\n",
       "         'value': 1.1942776}],\n",
       "       'value': 0.3435723}],\n",
       "     'value': 0.3435723},\n",
       "    '_id': '1',\n",
       "    '_index': 'my_index',\n",
       "    '_node': 'nKjjkxx5SfWhB1vabVu5ig',\n",
       "    '_score': 0.3435723,\n",
       "    '_shard': '[my_index][3]',\n",
       "    '_source': {'text': 'the chef is often the manager of the maid'},\n",
       "    '_type': 'test'},\n",
       "   {'_explanation': {'description': 'weight(text:cook in 0) [PerFieldSimilarity], result of:',\n",
       "     'details': [{'description': 'score(doc=0,freq=1.0 = termFreq=1.0\\n), product of:',\n",
       "       'details': [{'description': 'idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:',\n",
       "         'details': [{'description': 'docFreq', 'details': [], 'value': 1.0},\n",
       "          {'description': 'docCount', 'details': [], 'value': 1.0}],\n",
       "         'value': 0.2876821},\n",
       "        {'description': 'tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:',\n",
       "         'details': [{'description': 'termFreq=1.0',\n",
       "           'details': [],\n",
       "           'value': 1.0},\n",
       "          {'description': 'parameter k1', 'details': [], 'value': 1.2},\n",
       "          {'description': 'parameter b', 'details': [], 'value': 0.75},\n",
       "          {'description': 'avgFieldLength', 'details': [], 'value': 13.0},\n",
       "          {'description': 'fieldLength', 'details': [], 'value': 10.24}],\n",
       "         'value': 1.0951141}],\n",
       "       'value': 0.3150447}],\n",
       "     'value': 0.3150447},\n",
       "    '_id': '2',\n",
       "    '_index': 'my_index',\n",
       "    '_node': 'nKjjkxx5SfWhB1vabVu5ig',\n",
       "    '_score': 0.31504473,\n",
       "    '_shard': '[my_index][2]',\n",
       "    '_source': {'text': 'the cook is often the boss of the maid'},\n",
       "    '_type': 'test'},\n",
       "   {'_explanation': {'description': 'weight(text:cook in 0) [PerFieldSimilarity], result of:',\n",
       "     'details': [{'description': 'score(doc=0,freq=1.0 = termFreq=1.0\\n), product of:',\n",
       "       'details': [{'description': 'idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:',\n",
       "         'details': [{'description': 'docFreq', 'details': [], 'value': 1.0},\n",
       "          {'description': 'docCount', 'details': [], 'value': 1.0}],\n",
       "         'value': 0.2876821},\n",
       "        {'description': 'tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:',\n",
       "         'details': [{'description': 'termFreq=1.0',\n",
       "           'details': [],\n",
       "           'value': 1.0},\n",
       "          {'description': 'parameter k1', 'details': [], 'value': 1.2},\n",
       "          {'description': 'parameter b', 'details': [], 'value': 0.75},\n",
       "          {'description': 'avgFieldLength', 'details': [], 'value': 21.0},\n",
       "          {'description': 'fieldLength', 'details': [], 'value': 20.897959}],\n",
       "         'value': 1.0019919}],\n",
       "       'value': 0.28825513}],\n",
       "     'value': 0.28825513},\n",
       "    '_id': '3',\n",
       "    '_index': 'my_index',\n",
       "    '_node': 'nKjjkxx5SfWhB1vabVu5ig',\n",
       "    '_score': 0.2882551,\n",
       "    '_shard': '[my_index][4]',\n",
       "    '_source': {'text': 'the cook is often the boss of the maid and anyone else who hangs in the kitchen.'},\n",
       "    '_type': 'test'}],\n",
       "  'max_score': 0.3435723,\n",
       "  'total': 3},\n",
       " 'timed_out': False,\n",
       " 'took': 1}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = {\n",
    "  \"query\": {\n",
    "    \"match_phrase\": {\n",
    "      \"text\": {\n",
    "        \"query\": \"cook\",\n",
    "        \"analyzer\": \"my_synonyms\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "es.search(index='my_index', body=body, explain=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
