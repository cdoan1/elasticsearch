{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch: The Definitive Guide - Python\n",
    "\n",
    "Following the examples in the book, here are Python snippets that achieve the same effect.\n",
    "\n",
    "Documentation for the Python libs:\n",
    "\n",
    "Low-level API:\n",
    "\n",
    "https://elasticsearch-py.readthedocs.io/en/master/index.html\n",
    "\n",
    "Expressive DSL API (more \"Pythonic\")\n",
    "\n",
    "http://elasticsearch-dsl.readthedocs.io/en/latest/index.html\n",
    "\n",
    "Github repo for DSL API:\n",
    "\n",
    "https://github.com/elastic/elasticsearch-dsl-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 items created\n"
     ]
    }
   ],
   "source": [
    "import index\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q\n",
    "from pprint import pprint\n",
    "\n",
    "es = Elasticsearch(\n",
    "    'localhost',\n",
    "    # sniff before doing anything\n",
    "    sniff_on_start=True,\n",
    "    # refresh nodes after a node fails to respond\n",
    "    sniff_on_connection_fail=True,\n",
    "    # and also every 60 seconds\n",
    "    sniffer_timeout=60\n",
    ")\n",
    "\n",
    "r = index.populate()\n",
    "print('{} items created'.format(len(r['items'])))\n",
    "\n",
    "# Let's repopulate the index as we deleted 'gb' in earlier chapters:\n",
    "# Run the script: populate.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Synonyms\n",
    "\n",
    "#### Expand or contract\n",
    "\n",
    "It is possible to replace synonyms by simple expansion, simple contraction, or generic expansion. We will look at the trade-offs of each of these techniques in this section.\n",
    "\n",
    "#### Simple expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"my_synonym_filter\": {\n",
    "          \"type\": \"synonym\", \n",
    "          \"synonyms\": [ \n",
    "            \"jump,hop,leap\"\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_synonyms\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"my_synonym_filter\" \n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos 0: (the)\n",
      "Pos 1: (cow)\n",
      "Pos 2: (did)\n",
      "Pos 3: (not)\n",
      "Pos 4: (jump)\n",
      "Pos 4: (hop)\n",
      "Pos 4: (leap)\n",
      "Pos 5: (over)\n",
      "Pos 6: (the)\n",
      "Pos 7: (moon)\n"
     ]
    }
   ],
   "source": [
    "# test with my_synonyms\n",
    "text = \"the cow did not jump over the moon\" \n",
    "analyzed_text = [[x['position'],x['token']] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_synonyms', text=text)['tokens']]\n",
    "for item in analyzed_text:\n",
    "    print('Pos {}: ({})'.format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![screenshot 2017-03-13 11 59 34](https://cloud.githubusercontent.com/assets/28526/23870720/a15f6eac-07e4-11e7-8cfd-9099e087fd12.png)\n",
    "\n",
    "#### Simple contraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"my_synonym_filter\": {\n",
    "          \"type\": \"synonym\", \n",
    "          \"synonyms\": [ \n",
    "            \"leap,hop => jump\"\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_synonyms\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"my_synonym_filter\" \n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "    \"mappings\": {\n",
    "    \"test\": {\n",
    "      \"properties\": {\n",
    "        \"text\": {\n",
    "          \"type\":  \"text\",\n",
    "          \"analyzer\": \"my_synonyms\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos 0: (the)\n",
      "Pos 1: (cow)\n",
      "Pos 2: (did)\n",
      "Pos 3: (not)\n",
      "Pos 4: (jump)\n",
      "Pos 5: (over)\n",
      "Pos 6: (the)\n",
      "Pos 7: (moon)\n"
     ]
    }
   ],
   "source": [
    "# test with my_synonyms\n",
    "text = \"the cow did not leap over the moon\" \n",
    "analyzed_text = [[x['position'],x['token']] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_synonyms', text=text)['tokens']]\n",
    "for item in analyzed_text:\n",
    "    print('Pos {}: ({})'.format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It must be applied both at index time and at query time, to ensure that query terms are mapped to the same single value that exists in the index. Let's demonstrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '1',\n",
       " '_index': 'my_index',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'test',\n",
       " '_version': 1,\n",
       " 'created': True,\n",
       " 'result': 'created'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"the cow did not leap over the moon\" \n",
    "body = { \"text\": text }\n",
    "es.create(index='my_index', doc_type='test', body=body, id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/1): {'text': 'the cow did not leap over the moon'}>]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for hop \n",
    "s = Search(using=es)\n",
    "s = s.query('match', text='hop')\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screenshot 2017-03-13 12 25 10](https://cloud.githubusercontent.com/assets/28526/23871542/1d4c8556-07e8-11e7-8e47-c65a8eba39fa.png)\n",
    "\n",
    "#### Genre Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"my_synonym_filter\": {\n",
    "          \"type\": \"synonym\", \n",
    "          \"synonyms\": [ \n",
    "            \"cat    => cat,pet\",\n",
    "            \"kitten => kitten,cat,pet\",\n",
    "            \"dog    => dog,pet\",\n",
    "            \"puppy  => puppy,dog,pet\"\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_synonyms\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"my_synonym_filter\" \n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "    \"mappings\": {\n",
    "    \"test\": {\n",
    "      \"properties\": {\n",
    "        \"text\": {\n",
    "          \"type\":  \"text\",\n",
    "          \"analyzer\": \"my_synonyms\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos 0: (i)\n",
      "Pos 1: (am)\n",
      "Pos 2: (looking)\n",
      "Pos 3: (for)\n",
      "Pos 4: (a)\n",
      "Pos 5: (kitten)\n",
      "Pos 5: (cat)\n",
      "Pos 5: (pet)\n"
     ]
    }
   ],
   "source": [
    "# test with my_synonyms for kittens\n",
    "text = \"i am looking for a kitten\" \n",
    "analyzed_text = [[x['position'],x['token']] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_synonyms', text=text)['tokens']]\n",
    "for item in analyzed_text:\n",
    "    print('Pos {}: ({})'.format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos 0: (i)\n",
      "Pos 1: (am)\n",
      "Pos 2: (looking)\n",
      "Pos 3: (for)\n",
      "Pos 4: (a)\n",
      "Pos 5: (pet)\n"
     ]
    }
   ],
   "source": [
    "# But what about pets?\n",
    "text = \"i am looking for a pet\" \n",
    "analyzed_text = [[x['position'],x['token']] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_synonyms', text=text)['tokens']]\n",
    "for item in analyzed_text:\n",
    "    print('Pos {}: ({})'.format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no mapping for pet here, but that would be catered for in an indexed doc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '3',\n",
       " '_index': 'my_index',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'test',\n",
       " '_version': 1,\n",
       " 'created': True,\n",
       " 'result': 'created'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"who wants a dog?\" \n",
    "body = { \"text\": text }\n",
    "es.create(index='my_index', doc_type='test', body=body, id=1)\n",
    "text = \"who wants a cat?\" \n",
    "body = { \"text\": text }\n",
    "es.create(index='my_index', doc_type='test', body=body, id=2)\n",
    "text = \"who wants a kitten?\" \n",
    "body = { \"text\": text }\n",
    "es.create(index='my_index', doc_type='test', body=body, id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/3): {'text': 'who wants a kitten?'}>, <Hit(my_index/test/2): {'text': 'who wants a cat?'}>, <Hit(my_index/test/1): {'text': 'who wants a dog?'}>]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for a pet - ahhh, how cute!\n",
    "s = Search(using=es)\n",
    "s = s.query('match', text='can i find a pet?')\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also have the best of both worlds by applying expansion at index time to ensure that the genres are present in the index. Then, at query time, you can choose to not apply synonyms (so that a query for kitten returns only documents about kittens) or to apply synonyms in order to match kittens, cats and pets (including the canine variety).\n",
    "\n",
    "With the preceding example rules above, the IDF for kitten will be correct, while the IDF for cat and pet will be artificially deflated. However, this works in your favor—a genre-expanded query for kitten OR cat OR pet will rank documents with kitten highest, followed by documents with cat, and documents with pet would be right at the bottom.\n",
    "\n",
    "#### Synonyms and The Analysis Chain\n",
    "\n",
    "Imagine that we have an analyzer that consists of the standard tokenizer, with the lowercase token filter followed by a synonym token filter. The analysis process for the text U.S.A. would look like this:\n",
    "\n",
    "`\n",
    "original string                  → \"U.S.A.\"\n",
    "standard           tokenizer     → (U),(S),(A)\n",
    "lowercase          token filter  → (u),(s),(a)\n",
    "synonym            token filter  → (usa)\n",
    "`\n",
    "\n",
    "If we had specified the synonym as U.S.A., it would never match anything because, by the time my_synonym_filter sees the terms, the periods have been removed and the letters have been lowercased.\n",
    "\n",
    "This is an important point to consider. What if we want to combine synonyms with stemming, so that jumps, jumped, jump, leaps, leaped, and leap are all indexed as the single term jump? We could place the synonyms filter before the stemmer and list all inflections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '1',\n",
       " '_index': 'my_index',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'test',\n",
       " '_version': 1,\n",
       " 'created': True,\n",
       " 'result': 'created'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first without any stemmer - let's see what happens:\n",
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"my_synonym_filter\": {\n",
    "          \"type\": \"synonym\", \n",
    "          \"synonyms\": [ \n",
    "            \"jumps,jumped,leap,leaps,leaped => jump\"\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_synonyms\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"my_synonym_filter\" \n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "    \"mappings\": {\n",
    "    \"test\": {\n",
    "      \"properties\": {\n",
    "        \"text\": {\n",
    "          \"type\":  \"text\",\n",
    "          \"analyzer\": \"my_synonyms\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)\n",
    "text = \"the cow jumped over the moon\" \n",
    "body = { \"text\": text }\n",
    "es.create(index='my_index', doc_type='test', body=body, id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: []>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for a cow that jumps\n",
    "s = Search(using=es)\n",
    "q = Q('match', text='cow') & Q('match', text='jumps')\n",
    "s = s.query(q)\n",
    "s.execute()\n",
    "# it should work because we \"stemmed\" all terms via our synonyms contraction to jump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now consider an alternative strategy to use a stemmer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now with a stemmer\n",
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"my_synonym_filter\": {\n",
    "          \"type\": \"synonym\", \n",
    "          \"synonyms\": [ \n",
    "            \"leap => jump\"\n",
    "          ]\n",
    "        },\n",
    "        \"my_stemmer\": {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"english\" \n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_synonyms\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"my_stemmer\",\n",
    "            \"my_synonym_filter\" \n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "    \"mappings\": {\n",
    "    \"test\": {\n",
    "      \"properties\": {\n",
    "        \"text\": {\n",
    "          \"type\":  \"text\",\n",
    "          \"analyzer\": \"my_synonyms\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '1',\n",
       " '_index': 'my_index',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'test',\n",
       " '_version': 1,\n",
       " 'created': True,\n",
       " 'result': 'created'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"the cow jumped over the moon\" \n",
    "body = { \"text\": text }\n",
    "es.create(index='my_index', doc_type='test', body=body, id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/1): {'text': 'the cow jumped over the moon'}>]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for a cow that jumps\n",
    "s = Search(using=es)\n",
    "q = Q('match', text='jumps')\n",
    "s = s.query(q)\n",
    "s.execute()\n",
    "# it should work because we \"stemmed\" all terms via our synonyms contraction to jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/1): {'text': 'the cow jumped over the moon'}>]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But does it catch all those terms: jumps,jumped,leap,leaps,leaped and jumping?\n",
    "# search for a cow that jumps\n",
    "s = Search(using=es)\n",
    "q = Q('match', text='jumps') & Q('match', text='leap') & Q('match', text='leaps') & \\\n",
    "    Q('match', text='leaped') & Q('match', text='jumping')\n",
    "s = s.query(q)\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case-Sensitive Synonyms\n",
    "\n",
    "Synonym filters usually placed after lowercase filters. But what if we really want to check for `CAT scan` and not cats?\n",
    "\n",
    "Solution: create two synonym filters:\n",
    "\n",
    "##### Case-sensitive rules:\n",
    "\n",
    "`\"CAT,CAT scan           => cat_scan\"\n",
    "\"PET,PET scan           => pet_scan\"\n",
    "\"Johnny Little,J Little => johnny_little\"\n",
    "\"Johnny Small,J Small   => johnny_small\"\n",
    "`\n",
    "\n",
    "##### Case-insensitive rules:\n",
    "\n",
    "`\n",
    "\"cat                    => cat,pet\"\n",
    "\"dog                    => dog,pet\"\n",
    "\"cat scan,cat_scan scan => cat_scan\"\n",
    "\"pet scan,pet_scan scan => pet_scan\"\n",
    "\"little,small\"\n",
    "`\n",
    "\n",
    "Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# two sets of synonyms without a stemmer here:\n",
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"my_syns_1\": {\n",
    "          \"type\": \"synonym\", \n",
    "          \"synonyms\": [ \n",
    "            \"CAT,CAT scan           => cat_scan\",\n",
    "            \"PET,PET scan           => pet_scan\",\n",
    "            \"Johnny Little,J Little => johnny_little\",\n",
    "            \"Johnny Small,J Small   => johnny_small\"\n",
    "          ]\n",
    "        },\n",
    "        \"my_syns_2\": {\n",
    "          \"type\": \"synonym\", \n",
    "          \"synonyms\": [ \n",
    "            \"cat                    => cat,pet\",\n",
    "            \"dog                    => dog,pet\",\n",
    "            \"cat scan,cat_scan scan => cat_scan\",\n",
    "            \"pet scan,pet_scan scan => pet_scan\",\n",
    "            \"little,small\"\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_synonyms\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"my_syns_1\",\n",
    "            \"my_syns_2\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "    \"mappings\": {\n",
    "    \"test\": {\n",
    "      \"properties\": {\n",
    "        \"text\": {\n",
    "          \"type\":  \"text\",\n",
    "          \"analyzer\": \"my_synonyms\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)\n",
    "text = \"the man went to get a cat\" \n",
    "body = { \"text\": text }\n",
    "r = es.create(index='my_index', doc_type='test', body=body, id=1)\n",
    "text = \"the man went to get a CAT scan\" \n",
    "body = { \"text\": text }\n",
    "r = es.create(index='my_index', doc_type='test', body=body, id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/1): {'text': 'the man went to get a cat'}>]>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for a man with a cat\n",
    "s = Search(using=es)\n",
    "q = Q('match', text='cat')\n",
    "s = s.query(q)\n",
    "s.execute()\n",
    "# it should work because we \"stemmed\" all terms via our synonyms contraction to jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/2): {'text': 'the man went to get a CAT scan'}>]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for a man with a cat\n",
    "s = Search(using=es)\n",
    "q = Q('match', text='CAT')\n",
    "s = s.query(q)\n",
    "s.execute()\n",
    "# it should work because we \"stemmed\" all terms via our synonyms contraction to jump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiword Synonyms and Phrase Queries\n",
    "\n",
    "So far, synonyms appear to be quite straightforward. Unfortunately, this is where things start to go wrong. For phrase queries to function correctly, Elasticsearch needs to know the position that each term occupies in the original text. Multiword synonyms can play havoc with term positions, especially when the injected synonyms are of differing lengths.\n",
    "\n",
    "To demonstrate, we’ll create a synonym token filter that uses this rule:\n",
    "\n",
    "`\"usa,united states,u s a,united states of america\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"my_synonym_filter\": {\n",
    "          \"type\": \"synonym\",\n",
    "          \"synonyms\": [\n",
    "            \"usa,united states,u s a,united states of america\"\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_synonyms\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"my_synonym_filter\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos 0: (the)\n",
      "Pos 1: (united)\n",
      "Pos 1: (usa)\n",
      "Pos 1: (u)\n",
      "Pos 1: (united)\n",
      "Pos 2: (states)\n",
      "Pos 2: (s)\n",
      "Pos 2: (states)\n",
      "Pos 3: (is)\n",
      "Pos 3: (a)\n",
      "Pos 3: (of)\n",
      "Pos 4: (wealthy)\n",
      "Pos 4: (america)\n"
     ]
    }
   ],
   "source": [
    "# test with my_synonyms \n",
    "text = \"The United States is wealthy\" \n",
    "analyzed_text = [[x['position'],x['token']] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_synonyms', text=text)['tokens']]\n",
    "for item in analyzed_text:\n",
    "    print('Pos {}: ({})'.format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 1, 'total': 1},\n",
       " 'explanations': [{'explanation': 'text:\"(usa united u united) (is states s states) (wealthy a of) america\"',\n",
       "   'index': 'my_index',\n",
       "   'valid': True}],\n",
       " 'valid': True}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at this query validation:\n",
    "body = {\n",
    "  \"query\": {\n",
    "    \"match_phrase\": {\n",
    "      \"text\": {\n",
    "        \"query\": \"usa is wealthy\",\n",
    "        \"analyzer\": \"my_synonyms\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "es.indices.validate_query(index='my_index', body=body, explain=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any combination of the explained text would work for this query:\n",
    "\n",
    "`(usa united u united) (is states s states) (wealthy a of) america`\n",
    "\n",
    "* `usa is wealthy america`\n",
    "* `u is of america`\n",
    "* `usa states of america`\n",
    "\n",
    "What a mess!\n",
    "\n",
    "The way to avoid it is to use simple contract where possible to inject a single term that represents all synonyms and to use the same synonym token filter at query time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"my_synonym_filter\": {\n",
    "          \"type\": \"synonym\",\n",
    "          \"synonyms\": [\n",
    "            \"united states,u s a,united states of america=>usa\"\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_synonyms\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"my_synonym_filter\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos 0: (the)\n",
      "Pos 1: (usa)\n",
      "Pos 2: (is)\n",
      "Pos 3: (wealthy)\n"
     ]
    }
   ],
   "source": [
    "# test it now\n",
    "text = \"The United States is wealthy\" \n",
    "analyzed_text = [[x['position'],x['token']] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_synonyms', text=text)['tokens']]\n",
    "for item in analyzed_text:\n",
    "    print('Pos {}: ({})'.format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 1, 'total': 1},\n",
       " 'explanations': [{'explanation': 'text:\"usa is wealthy\"',\n",
       "   'index': 'my_index',\n",
       "   'valid': True}],\n",
       " 'valid': True}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now validate the query again:\n",
    "body = {\n",
    "  \"query\": {\n",
    "    \"match_phrase\": {\n",
    "      \"text\": {\n",
    "        \"query\": \"usa is wealthy\",\n",
    "        \"analyzer\": \"my_synonyms\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "es.indices.validate_query(index='my_index', body=body, explain=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Symbol Synonyms\n",
    "\n",
    "I am thrilled to be at work on Sunday.\n",
    "I am thrilled to be at work on Sunday :(\n",
    "\n",
    "The second string would have the emoticon stripped out.\n",
    "\n",
    "If we want to handle emoticons, then create a mapping character filter:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"char_filter\": {\n",
    "        \"emoticons\": {\n",
    "          \"type\": \"mapping\",\n",
    "          \"mappings\": [ \n",
    "            \":)=>emoticon_happy\",\n",
    "            \":(=>emoticon_sad\"\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_emoticons\": {\n",
    "          \"char_filter\": \"emoticons\",\n",
    "          \"tokenizer\":   \"standard\",\n",
    "          \"filter\":    [ \"lowercase\" ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos 0: (i)\n",
      "Pos 1: (am)\n",
      "Pos 2: (emoticon_happy)\n",
      "Pos 3: (not)\n",
      "Pos 4: (emoticon_sad)\n"
     ]
    }
   ],
   "source": [
    "# test with my_synonyms - let's see what the analyzer does with our => mappings:\n",
    "text = \"I am :) not :(\" \n",
    "analyzed_text = [[x['position'],x['token']] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_emoticons', text=text)['tokens']]\n",
    "for item in analyzed_text:\n",
    "    print('Pos {}: ({})'.format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is unlikely that anybody would ever search for emoticon_happy, but ensuring that important symbols like emoticons are included in the index can be helpful when doing sentiment analysis. Of course, we could equally have used real words, like happy and sad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
