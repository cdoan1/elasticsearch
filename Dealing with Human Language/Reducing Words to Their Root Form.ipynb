{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch: The Definitive Guide - Python\n",
    "\n",
    "Following the examples in the book, here are Python snippets that achieve the same effect.\n",
    "\n",
    "Documentation for the Python libs:\n",
    "\n",
    "Low-level API:\n",
    "\n",
    "https://elasticsearch-py.readthedocs.io/en/master/index.html\n",
    "\n",
    "Expressive DSL API (more \"Pythonic\")\n",
    "\n",
    "http://elasticsearch-dsl.readthedocs.io/en/latest/index.html\n",
    "\n",
    "Github repo for DSL API:\n",
    "\n",
    "https://github.com/elastic/elasticsearch-dsl-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 items created\n"
     ]
    }
   ],
   "source": [
    "import index\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q\n",
    "from pprint import pprint\n",
    "\n",
    "es = Elasticsearch(\n",
    "    'localhost',\n",
    "    # sniff before doing anything\n",
    "    sniff_on_start=True,\n",
    "    # refresh nodes after a node fails to respond\n",
    "    sniff_on_connection_fail=True,\n",
    "    # and also every 60 seconds\n",
    "    sniffer_timeout=60\n",
    ")\n",
    "\n",
    "r = index.populate()\n",
    "print('{} items created'.format(len(r['items'])))\n",
    "\n",
    "# Let's repopulate the index as we deleted 'gb' in earlier chapters:\n",
    "# Run the script: populate.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reducing Words to Their Root Form\n",
    "\n",
    "Most languages of the world are inflected, meaning that words can change their form to express differences in the following:\n",
    "\n",
    "* Number: fox, foxes\n",
    "* Tense: pay, paid, paying\n",
    "* Gender: waiter, waitress\n",
    "* Person: hear, hears\n",
    "* Case: I, me, my\n",
    "* Aspect: ate, eaten\n",
    "* Mood: so be it, were it so\n",
    "\n",
    "While inflection aids expressivity, it interferes with retrievability, as a single root word sense (or meaning) may be represented by many different sequences of letters\n",
    "\n",
    "Stemming attempts to remove the differences between inflected forms of a word, in order to reduce each word to its root form. For instance foxes may be reduced to the root fox.\n",
    "\n",
    "If stemming were easy, there would be only one implementation. Unfortunately, stemming is an inexact science that suffers from two issues: understemming and overstemming.\n",
    "\n",
    "**The root form of a word may not even be a real word**. The words ```jumping``` and ```jumpiness``` may both be stemmed to ```jumpi```. It doesn’t matter—as long as the same terms are produced at index time and at search time, search will just work.\n",
    "\n",
    "Understemming is the failure to reduce words with the same meaning to the same root. For example, ```jumped``` and ```jumps``` may be reduced to ```jump```, while ```jumping``` may be reduced to ```jumpi```. **Understemming reduces retrieval**; relevant documents are not returned.\n",
    "\n",
    "Overstemming is the failure to keep two words with distinct meanings separate. For instance, ```general``` and ```generate``` may both be stemmed to ```gener```. **Overstemming reduces precision**: irrelevant documents are returned when they shouldn’t be.\n",
    "\n",
    "#### Lemmatization ####\n",
    "\n",
    "A lemma is the canonical, or dictionary, form of a set of related words—the lemma of paying, paid, and pays is pay. Sometimes the morphology differs: is, was, am, and being is be.\n",
    "\n",
    "Lemmatization, like stemming, tries to group related words, but it goes one step further than stemming in that it tries to group words by their word sense, or meaning. The same word may represent two meanings—for example,wake can mean to wake up or a funeral. While lemmatization would try to distinguish these two word senses, stemming would incorrectly conflate them.\n",
    "\n",
    "Lemmatization is a much more complicated and expensive process that needs to understand the context in which words appear in order to make decisions about what they mean. In practice, stemming appears to be just as effective as lemmatization, but with a much lower cost.\n",
    "\n",
    "### Algorithmic Stemmers\n",
    "\n",
    "While you can use the porter_stem or kstem token filter directly, or create a language-specific Snowball stemmer with the snowball token filter, all of the algorithmic stemmers are exposed via a single unified interface: the stemmer token filter, which accepts the language parameter.\n",
    "\n",
    "For instance, perhaps you find the default stemmer used by the english analyzer to be too aggressive and you want to make it less aggressive. The first step is to look up the configuration for the english analyzer in the language analyzers documentation, which shows the following:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"english_stop\": {\n",
    "          \"type\":       \"stop\",\n",
    "          \"stopwords\":  \"_english_\"\n",
    "        },\n",
    "        \"english_keywords\": {\n",
    "          \"type\":       \"keyword_marker\", \n",
    "          \"keywords\":   []\n",
    "        },\n",
    "        \"english_stemmer\": {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"english\" \n",
    "        },\n",
    "        \"english_possessive_stemmer\": {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"possessive_english\" \n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"english\": {\n",
    "          \"tokenizer\":  \"standard\",\n",
    "          \"filter\": [\n",
    "            \"english_possessive_stemmer\",\n",
    "            \"lowercase\",\n",
    "            \"english_stop\",\n",
    "            \"english_keywords\",\n",
    "            \"english_stemmer\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "The \"lighter\" modified English token filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "english_token_filter = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"english_stop\": {\n",
    "          \"type\":       \"stop\",\n",
    "          \"stopwords\":  \"_english_\"\n",
    "        },\n",
    "        \"light_english_stemmer\": {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"light_english\" \n",
    "        },\n",
    "        \"english_possessive_stemmer\": {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"possessive_english\"\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_english\": {\n",
    "          \"tokenizer\":  \"standard\",\n",
    "          \"filter\": [\n",
    "            \"english_possessive_stemmer\",\n",
    "            \"lowercase\",\n",
    "            \"english_stop\",\n",
    "            \"light_english_stemmer\", \n",
    "            \"asciifolding\" \n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index.create_my_index(body=english_token_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's put some data into my_index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '1',\n",
       " '_index': 'my_index',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'test',\n",
       " '_version': 1,\n",
       " 'created': True,\n",
       " 'result': 'created'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"You're right about those jumping jacks in the Über generation of waiters.\"\n",
    "doc = {\n",
    "    \"message\": text\n",
    "}\n",
    "es.create(index=\"my_index\", doc_type='test', body=doc, id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you'r,right,about,those,jump,jack,über,gener,waiter\n"
     ]
    }
   ],
   "source": [
    "# test with the standard English analyzer\n",
    "analyzed_text = [x['token'] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='english', text=text)['tokens']]\n",
    "print(','.join(analyzed_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the singlular from plural ('jack(s)'), notice the following mappings:\n",
    "\n",
    "* many => mani\n",
    "* jumping => jump\n",
    "* generation => gener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you're,right,about,those,jump,jack,uber,generation,waiter\n"
     ]
    }
   ],
   "source": [
    "# test with the modified English analyzer - 'my_english'\n",
    "analyzed_text = [x['token'] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_english', text=text)['tokens']]\n",
    "print(','.join(analyzed_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the singlular from plural ('jack(s)'), notice the different mappings:\n",
    "\n",
    "* many => many (same i.e. non-stemmed)\n",
    "* generation => generation (same e.g. non-stemmed)\n",
    "* Über => uber (i.e. asciifolded)\n",
    "\n",
    "But what if we search for one of these transformed words in the docs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: []>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Search(using=es, index=\"my_index\").query('match', message=\"jump uber\")\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm. No results for ```jump```. How come?\n",
    "Let's check the mapping for the field ```message```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'my_index': {'mappings': {'test': {'properties': {'message': {'fields': {'keyword': {'ignore_above': 256,\n",
       "        'type': 'keyword'}},\n",
       "      'type': 'text'}}}}}}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = es.indices.get_mapping(index='my_index', doc_type='test')\n",
    "res\n",
    "#es.indices.get_field_mapping(index='my_index', fields='messages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our analyzer has not been mapped. Let's do it now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "english_token_filter = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"english_stop\": {\n",
    "          \"type\":       \"stop\",\n",
    "          \"stopwords\":  \"_english_\"\n",
    "        },\n",
    "        \"light_english_stemmer\": {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"light_english\" \n",
    "        },\n",
    "        \"english_possessive_stemmer\": {\n",
    "          \"type\":       \"stemmer\",\n",
    "          \"language\":   \"possessive_english\"\n",
    "        }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_english\": {\n",
    "          \"tokenizer\":  \"standard\",\n",
    "          \"filter\": [\n",
    "            \"english_possessive_stemmer\",\n",
    "            \"lowercase\",\n",
    "            \"english_stop\",\n",
    "            \"light_english_stemmer\", \n",
    "            \"asciifolding\" \n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "    \"mappings\": {\n",
    "    \"test\" : {\n",
    "      \"properties\" : {\n",
    "        \"message\" : {\n",
    "          \"type\" :    \"text\",\n",
    "          \"analyzer\": \"my_english\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=english_token_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '1',\n",
       " '_index': 'my_index',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'test',\n",
       " '_version': 1,\n",
       " 'created': True,\n",
       " 'result': 'created'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"You're right about those jumping jacks in the Über generation of waiters.\"\n",
    "doc = {\n",
    "    \"message\": text\n",
    "}\n",
    "es.create(index=\"my_index\", doc_type='test', body=doc, id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "You're right about those jumping jacks in the Über generation of waiters.\n"
     ]
    }
   ],
   "source": [
    "s = Search(using=es, index=\"my_index\", doc_type='test').query('match', message=\"jump\")\n",
    "res = s.execute()\n",
    "print(res.hits.total)\n",
    "print(res[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "You're right about those jumping jacks in the Über generation of waiters.\n"
     ]
    }
   ],
   "source": [
    "s = Search(using=es, index=\"my_index\", doc_type='test').query('match', message=\"uber\")\n",
    "res = s.execute()\n",
    "print(res.hits.total)\n",
    "print(res[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
