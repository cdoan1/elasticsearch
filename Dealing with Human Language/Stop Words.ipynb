{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch: The Definitive Guide - Python\n",
    "\n",
    "Following the examples in the book, here are Python snippets that achieve the same effect.\n",
    "\n",
    "Documentation for the Python libs:\n",
    "\n",
    "Low-level API:\n",
    "\n",
    "https://elasticsearch-py.readthedocs.io/en/master/index.html\n",
    "\n",
    "Expressive DSL API (more \"Pythonic\")\n",
    "\n",
    "http://elasticsearch-dsl.readthedocs.io/en/latest/index.html\n",
    "\n",
    "Github repo for DSL API:\n",
    "\n",
    "https://github.com/elastic/elasticsearch-dsl-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 items created\n"
     ]
    }
   ],
   "source": [
    "import index\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q\n",
    "from pprint import pprint\n",
    "\n",
    "es = Elasticsearch(\n",
    "    'localhost',\n",
    "    # sniff before doing anything\n",
    "    sniff_on_start=True,\n",
    "    # refresh nodes after a node fails to respond\n",
    "    sniff_on_connection_fail=True,\n",
    "    # and also every 60 seconds\n",
    "    sniffer_timeout=60\n",
    ")\n",
    "\n",
    "r = index.populate()\n",
    "print('{} items created'.format(len(r['items'])))\n",
    "\n",
    "# Let's repopulate the index as we deleted 'gb' in earlier chapters:\n",
    "# Run the script: populate.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Stop Words\n",
    "\n",
    "#### Stopwords and the Standard Analyzer\n",
    "\n",
    "To use custom stopwords in conjunction with the standard analyzer, all we need to do is to create a configured version of the analyzer and pass in the list of stopwords that we require:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"my_analyzer\": { \n",
    "          \"type\": \"standard\", \n",
    "          \"stopwords\": [ \"and\", \"the\" ] \n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the,quick,and,the,dead\n"
     ]
    }
   ],
   "source": [
    "# test with the __standard__analyzer\n",
    "text = \"The quick and the dead.\" \n",
    "analyzed_text = [x['token'] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='standard', text=text)['tokens']]\n",
    "print(','.join(analyzed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick,dead\n"
     ]
    }
   ],
   "source": [
    "# test with my_analyzer\n",
    "text = \"The quick and the dead.\" \n",
    "analyzed_text = [x['token'] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_analyzer', text=text)['tokens']]\n",
    "print(','.join(analyzed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [{'end_offset': 9,\n",
       "   'position': 1,\n",
       "   'start_offset': 4,\n",
       "   'token': 'quick',\n",
       "   'type': '<ALPHANUM>'},\n",
       "  {'end_offset': 22,\n",
       "   'position': 4,\n",
       "   'start_offset': 18,\n",
       "   'token': 'dead',\n",
       "   'type': '<ALPHANUM>'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the word positions (quick - pos 1, dead - pos 4) have been maintained:\n",
    "es.indices.analyze(index='my_index', analyzer='my_analyzer', text=text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word position integrity (per above example) is important for phrase queries â€” if the positions of each term had been adjusted, a phrase query for quick dead would have matched the preceding example incorrectly.\n",
    "\n",
    "Note that the ```stopwords``` field accepts a range of settings:\n",
    "\n",
    "##### Array of stop words\n",
    "\n",
    "> ```\"stopwords\": [ \"and\", \"the\" ]```\n",
    "\n",
    "##### Default language stopwords\n",
    "\n",
    "> ```\"stopwords\": \"_english_\"```\n",
    "\n",
    "##### No stopwords\n",
    "\n",
    "> ```\"stopwords\": \"_none_\"```\n",
    "\n",
    "The default stopwords for `_english_`:\n",
    "\n",
    "```a, an, and, are, as, at, be, but, by, for, if, in, into, is, it,\n",
    "no, not, of, on, or, such, that, the, their, then, there, these,\n",
    "they, this, to, was, will, with```\n",
    "\n",
    "Note that stopwords can be placed in a file (default config/stopwords).\n",
    "I placed a file <es-home>/config/stopwords/english.txt with contents:\n",
    "```\n",
    "a\n",
    "the\n",
    "dead\n",
    "```\n",
    "i.e. one stopword per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "settings={\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"my_english\": {\n",
    "          \"type\":           \"english\",\n",
    "          \"stopwords_path\": \"stopwords/english.txt\" \n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "index.create_my_index(body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick,and,is,good,film\n"
     ]
    }
   ],
   "source": [
    "# test with my_analyzer\n",
    "text = \"The quick and the dead is a good film.\" \n",
    "analyzed_text = [x['token'] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='my_english', text=text)['tokens']]\n",
    "print(','.join(analyzed_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating stopwords is easier if you specify them in a file with the stopwords_path parameter. You can just update the file (on every node in the cluster) and then force the analyzers to be re-created by either of these actions:\n",
    "\n",
    "Closing and reopening the index (see open/close index), or\n",
    "Restarting each node in the cluster, one by one\n",
    "Of course, updating the stopwords list will not change any documents that have already been indexed. It will apply only to searches and to new or updated documents. To apply the changes to existing documents, you will need to reindex your data. See [Reindexing Your Data](https://www.elastic.co/guide/en/elasticsearch/guide/master/reindex.html).\n",
    "\n",
    "#### and Operator\n",
    "\n",
    "Search for \"quick and the dead\" is really search:\n",
    "\n",
    ">`quick OR and OR the OR dead`\n",
    "\n",
    "This is problematic because every doc containing any of those words needs to be included in the calculation of relevance (`_score`).\n",
    "\n",
    "A more precise search might be:\n",
    "\n",
    ">`quick AND and AND the AND dead`\n",
    "\n",
    "`\n",
    "{\n",
    "    \"match\": {\n",
    "        \"title\": {\n",
    "            \"query\":    \"quick and the dead\",\n",
    "            \"operator\": \"and\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '1',\n",
       " '_index': 'my_index',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'test',\n",
       " '_version': 1,\n",
       " 'created': True,\n",
       " 'result': 'created'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = { 'title': 'The quick and the dead is a good film.'}\n",
    "es.create(index='my_index', doc_type='test', body=body, id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '2',\n",
       " '_index': 'my_index',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'test',\n",
       " '_version': 1,\n",
       " 'created': True,\n",
       " 'result': 'created'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = { 'title': 'The quick and the alive is a bad film.'}\n",
    "es.create(index='my_index', doc_type='test', body=body, id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/1): {'title': 'The quick and the dead is a good film.'}>, <Hit(my_index/test/2): {'title': 'The quick and the alive is a bad film.'}>]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Search(using=es)\n",
    "s = s.query('match', title='the quick and the dead')\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = {\n",
    "    \"match\": {\n",
    "        \"title\": {\n",
    "            \"query\":    \"quick and the dead\",\n",
    "            \"operator\": \"and\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/1): {'title': 'The quick and the dead is a good film.'}>]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = Q(q)\n",
    "s = Search(using=es).query(q)\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/1): {'title': 'The quick and the dead is a good film.'}>]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same as this:\n",
    "q = Q('term', title='quick') & Q('term', title='and') \\\n",
    "    & Q('term', title='the')\\\n",
    "    & Q('term', title='dead')\n",
    "s = Search(using=es).query(q)\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/1): {'title': 'The quick and the dead is a good film.'}>]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same as this:\n",
    "q = Q('bool',\n",
    "      must=[Q('term', title='quick'), Q('term', title='and'), \\\n",
    "            Q('term', title='the'), Q('term', title='dead')])\n",
    "s = Search(using=es).query(q)\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can narrow the results by the `minimum_should_match` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = {\n",
    "    \"match\": {\n",
    "        \"title\": {\n",
    "            \"query\":    \"quick dead good film\",\n",
    "            \"minimum_should_match\": \"100%\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/1): {'title': 'The quick and the dead is a good film.'}>]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100% of terms should match - all 4 of them\n",
    "q = Q(q)\n",
    "s = Search(using=es).query(q)\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/1): {'title': 'The quick and the dead is a good film.'}>]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 75% of terms should match - any 3 of them\n",
    "q = {\n",
    "    \"match\": {\n",
    "        \"title\": {\n",
    "            \"query\":    \"quick dead good film\",\n",
    "            \"minimum_should_match\": \"75%\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "q = Q(q)\n",
    "s = Search(using=es).query(q)\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/test/2): {'title': 'The quick and the alive is a bad film.'}>, <Hit(my_index/test/1): {'title': 'The quick and the dead is a good film.'}>]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 50% of terms should match - any 2 of them\n",
    "q = {\n",
    "    \"match\": {\n",
    "        \"title\": {\n",
    "            \"query\":    \"quick dead alive film\",\n",
    "            \"minimum_should_match\": \"50%\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "q = Q(q)\n",
    "s = Search(using=es).query(q)\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This offers a huge performance gain over a simple query with the default or operator! But we can do better yet...\n",
    "\n",
    "#### Divide and Conquer\n",
    "\n",
    "The terms in a query string can be divided into more-important (low-frequency) and less-important (high-frequency) terms. Documents that match only the less important terms are probably of very little interest. Really, we want documents that match as many of the more important terms as possible.\n",
    "\n",
    "The match query accepts a cutoff_frequency parameter, which allows it to divide the terms in the query string into a low-frequency and high-frequency group.\n",
    "\n",
    "First, consider the scores for the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick and the alive is a bad film. 0.8169974 2\n",
      "The quick and the dead is a good film. 0.8169974 1\n"
     ]
    }
   ],
   "source": [
    "# 50% of terms should match - any 2 of them\n",
    "q = {\n",
    "    \"match\": {\n",
    "        \"title\": {\n",
    "            \"query\":    \"quick dead alive film\",\n",
    "            \"minimum_should_match\": \"50%\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "q = Q(q)\n",
    "s = Search(using=es).query(q)\n",
    "res = s.execute()\n",
    "for hit in res:\n",
    "    print(hit.title, hit.meta.score, hit.meta.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected these have identical scores:\n",
    "\n",
    "* quick dead is in doc id=1\n",
    "* quick alive is in doc id=2\n",
    "\n",
    "Let's consider a strategy for \"high frequency\" group and \"low frequency\" group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = {\n",
    "  \"bool\": {\n",
    "    \"must\": { \n",
    "      \"bool\": {\n",
    "        \"should\": [\n",
    "          { \"term\": { \"title\": \"alive\" }},\n",
    "          { \"term\": { \"title\": \"dead\"  }},\n",
    "        ]\n",
    "      }\n",
    "    },\n",
    "    \"should\": { \n",
    "      \"bool\": {\n",
    "        \"should\": [\n",
    "          { \"term\": { \"title\": \"film\" }},\n",
    "          { \"term\": { \"title\": \"good\" }}\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick and the dead is a good film. 0.8169974 1\n",
      "The quick and the alive is a bad film. 0.5446649 2\n"
     ]
    }
   ],
   "source": [
    "q = Q(q)\n",
    "s = Search(using=es).query(q)\n",
    "res = s.execute()\n",
    "for hit in res:\n",
    "    print(hit.title, hit.meta.score, hit.meta.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the film id=1 now wins (higher relevance _score) because:\n",
    "\n",
    "1. It contains the mandatory term \"dead\" (which it must)\n",
    "2. And it contains **two** of the low freq terms: \"film\" and \"good\"\n",
    "\n",
    "film id=2 contains the mandatory term \"alive\" but then only **one** of the low-frequency terms: \"film\".\n",
    "\n",
    "#### Stopwords and Phrase Queries\n",
    "\n",
    "** TO BE COMPLETED **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
