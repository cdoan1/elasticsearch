{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch: The Definitive Guide - Python\n",
    "\n",
    "Following the examples in the book, here are Python snippets that achieve the same effect.\n",
    "\n",
    "Documentation for the Python libs:\n",
    "\n",
    "Low-level API:\n",
    "\n",
    "https://elasticsearch-py.readthedocs.io/en/master/index.html\n",
    "\n",
    "Expressive DSL API (more \"Pythonic\")\n",
    "\n",
    "http://elasticsearch-dsl.readthedocs.io/en/latest/index.html\n",
    "\n",
    "Github repo for DSL API:\n",
    "\n",
    "https://github.com/elastic/elasticsearch-dsl-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q\n",
    "\n",
    "es = Elasticsearch(\n",
    "    'localhost',\n",
    "    # sniff before doing anything\n",
    "    sniff_on_start=True,\n",
    "    # refresh nodes after a node fails to respond\n",
    "    sniff_on_connection_fail=True,\n",
    "    # and also every 60 seconds\n",
    "    sniffer_timeout=60\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empty Search\n",
    "From: https://www.elastic.co/guide/en/elasticsearch/guide/master/empty-search.html\n",
    "\n",
    ">GET _search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = es.search('_all') # same as es.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from pprint import pprint\n",
    "#pprint(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(.kibana/config/5.2.2): {'discover:aggs:terms:size': 20, 'defaultIndex': 'test', 'bu...}>, <Hit(.kibana/index-pattern/test): {'fields': '[{\"name\":\"tags\",\"type\":\"string\",\"count\":0,\"scrip...}>, <Hit(.kibana/index-pattern/megacorp): {'fields': '[{\"name\":\"last_name.keyword\",\"type\":\"string\",\"co...}>, <Hit(.kibana/index-pattern/website): {'fields': '[{\"name\":\"date\",\"type\":\"date\",\"count\":0,\"scripte...}>, <Hit(us/tweet/14): {'date': '2014-09-24', 'tweet': 'How many more cheesy tweets...}>, <Hit(gb/tweet/5): {'date': '2014-09-15', 'tweet': 'However did I manage before...}>, <Hit(gb/tweet/9): {'date': '2014-09-19', 'tweet': 'Geo-location aggregations a...}>, <Hit(us/tweet/8): {'date': '2014-09-18', 'name': 'John Smith', 'user_id': 1}>, <Hit(us/tweet/10): {'date': '2014-09-20', 'tweet': 'Elasticsearch surely is one...}>, <Hit(us/tweet/12): {'date': '2014-09-22', 'tweet': 'Elasticsearch and I have le...}>]>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Search(using=es)\n",
    "response = s.execute()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With timeout:\n",
    "\n",
    ">GET /_search?timeout=10ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = es.search('_all', timeout='10ms') # same as es.search(timeout='10ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Hit(us/tweet/14): {'date': '2014-09-24', 'tweet': 'How many more cheesy tweets...}>\n",
      "<Hit(gb/tweet/5): {'date': '2014-09-15', 'tweet': 'However did I manage before...}>\n",
      "<Hit(gb/tweet/9): {'date': '2014-09-19', 'tweet': 'Geo-location aggregations a...}>\n",
      "<Hit(us/tweet/8): {'date': '2014-09-18', 'name': 'John Smith', 'user_id': 1}>\n",
      "<Hit(us/tweet/10): {'date': '2014-09-20', 'tweet': 'Elasticsearch surely is one...}>\n",
      "<Hit(us/tweet/12): {'date': '2014-09-22', 'tweet': 'Elasticsearch and I have le...}>\n",
      "<Hit(gb/user/2): {'email': 'mary@jones.com', 'name': 'Mary Jones', 'username'...}>\n",
      "<Hit(us/tweet/4): {'date': '2014-09-14', 'tweet': '@mary it is not just text, ...}>\n",
      "<Hit(us/tweet/6): {'date': '2014-09-16', 'tweet': 'The Elasticsearch API is re...}>\n",
      "<Hit(gb/tweet/7): {'date': '2014-09-17', 'tweet': 'The Query DSL is really pow...}>\n"
     ]
    }
   ],
   "source": [
    "# To see the results, we can iterate:\n",
    "# Elasticsearch pages the results (to 10 hits)\n",
    "for hit in s:\n",
    "    print(hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-index, Multitype\n",
    "\n",
    "First using the low-level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "#/_search\n",
    "#Search all types in all indices\n",
    "res = es.search('_all')\n",
    "\n",
    "#/gb/_search\n",
    "#Search all types in the gb index\n",
    "res = es.search(index='gb')\n",
    "\n",
    "#/gb,us/_search\n",
    "#Search all types in the gb and us indices\n",
    "res = es.search(index=['gb','us'])\n",
    "\n",
    "#/g*,u*/_search\n",
    "#Search all types in any indices beginning with g or beginning with u\n",
    "res = es.search(index=['g*','u*'])\n",
    "\n",
    "#/gb/user/_search\n",
    "#Search type user in the gb index\n",
    "res = es.search(index='gb', doc_type='user')\n",
    "\n",
    "#/gb,us/user,tweet/_search\n",
    "#Search types user and tweet in the gb and us indices\n",
    "res = es.search(index=['g*','u*'], doc_type=['user', 'tweet'])\n",
    "print(res['hits']['total'])\n",
    "\n",
    "#/_all/user,tweet/_search\n",
    "#Search types user and tweet in all indices\n",
    "res = es.search(doc_type=['user', 'tweet'])\n",
    "print(res['hits']['total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next using the DSL, although similar for such basic searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#/_search\n",
    "#Search all types in all indices\n",
    "s = Search(using=es)\n",
    "response = s.execute()\n",
    "\n",
    "#/gb/_search\n",
    "#Search all types in the gb index\n",
    "s = Search(using=es, index='gb')\n",
    "response = s.execute()\n",
    "\n",
    "#/gb,us/_search\n",
    "#Search all types in the gb and us indices\n",
    "s = Search(using=es, index=['gb','us'])\n",
    "response = s.execute()\n",
    "\n",
    "#/g*,u*/_search\n",
    "#Search all types in any indices beginning with g or beginning with u\n",
    "s = Search(using=es, index=['g*','u*'])\n",
    "response = s.execute()\n",
    "\n",
    "#/gb/user/_search\n",
    "#Search type user in the gb index\n",
    "s = Search(using=es, index=['g*','u*'], doc_type='user')\n",
    "response = s.execute()\n",
    "\n",
    "\n",
    "#/gb,us/user,tweet/_search\n",
    "#Search types user and tweet in the gb and us indices\n",
    "s = Search(using=es, index=['g*','u*'], doc_type=['user','tweet'])\n",
    "response = s.execute()\n",
    "\n",
    "#/_all/user,tweet/_search\n",
    "#Search types user and tweet in all indices\n",
    "s = Search(using=es, doc_type=['user','tweet'])\n",
    "response = s.execute()\n",
    "print(response['hits']['total'])\n",
    "print(len(res['hits']['hits']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pagination\n",
    "\n",
    "The last search produced a hits total of 14, but there are only 10 documents in the array.\n",
    "\n",
    "This is due to pagination, so we need to use pointers:\n",
    "\n",
    ">GET /_search?size=5\n",
    "\n",
    ">GET /_search?size=5&from=5\n",
    "\n",
    ">GET /_search?size=5&from=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For search API:\n",
    "res = es.search(doc_type=['user', 'tweet'], from_=5, size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(res['hits']['total'])\n",
    "print(len(res['hits']['hits']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Lite\n",
    "\n",
    "These initial searches all use the Lucene Query String Syntax.\n",
    "\n",
    ">GET /_all/tweet/_search?q=tweet:elasticsearch\n",
    "\n",
    "For the low-level API, we use the q parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits:7\n",
      "\n",
      "{'_id': '13',\n",
      " '_index': 'gb',\n",
      " '_score': 0.7081689,\n",
      " '_source': {'date': '2014-09-23',\n",
      "             'name': 'Mary Jones',\n",
      "             'tweet': 'So yes, I am an Elasticsearch fanboy',\n",
      "             'user_id': 2},\n",
      " '_type': 'tweet'}\n"
     ]
    }
   ],
   "source": [
    "res = es.search(doc_type=['tweet'], q='tweet:elasticsearch')\n",
    "print('Total hits:{}\\n'.format(res['hits']['total']))\n",
    "pprint(res['hits']['hits'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the DSL, the intended purpose is to avoid the query string syntax and use the query string language instead. For completeness, here is an equivalent script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits:7\n",
      "\n",
      "{'_source': {'date': '2014-09-23', 'tweet': 'So yes, I am an...}\n"
     ]
    }
   ],
   "source": [
    "s = Search(using=es, doc_type=['tweet']) \\\n",
    "    .query('match', tweet='elasticsearch')\n",
    "response = s.execute()\n",
    "print('Total hits:{}\\n'.format(response['hits']['total']))\n",
    "pprint(response['hits']['hits'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, notice that the pprint has not given us the same JSON response as the above query string syntax result via the low-level API. This is because the Search() object returns an array of Hit objects. These are constructed so as to expose the individual fields as object attributes (__getattr__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So yes, I am an Elasticsearch fanboy\n",
      "However did I manage before Elasticsearch?\n",
      "The Elasticsearch API is really easy to use\n",
      "Elasticsearch surely is one of the hottest new NoSQL products\n",
      "Elasticsearch means full text search has never been so easy\n",
      "Elasticsearch is built for the cloud, easy to scale\n",
      "Elasticsearch and I have left the honeymoon stage, and I still love her.\n"
     ]
    }
   ],
   "source": [
    "for hit in response:\n",
    "    print(hit.tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The _all field\n",
    "\n",
    "> GET /_search?q=mary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits:8\n",
      "\n",
      "{'_id': '4',\n",
      " '_index': 'us',\n",
      " '_score': 0.6650044,\n",
      " '_source': {'date': '2014-09-14',\n",
      "             'name': 'John Smith',\n",
      "             'tweet': '@mary it is not just text, it does everything',\n",
      "             'user_id': 1},\n",
      " '_type': 'tweet'}\n"
     ]
    }
   ],
   "source": [
    "res = es.search(q='mary')\n",
    "print('Total hits:{}\\n'.format(res['hits']['total']))\n",
    "pprint(res['hits']['hits'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the DSL, we need to call the _all field explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits:8\n",
      "\n",
      "@mary it is not just text, it does everything\n"
     ]
    }
   ],
   "source": [
    "s = Search(using=es) \\\n",
    "    .query('match', _all='mary')\n",
    "response = s.execute()\n",
    "print('Total hits:{}\\n'.format(response['hits']['total']))\n",
    "print(response[0].tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> +name:(mary john) +date:>2014-09-10 +(aggregations geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits:1\n",
      "\n",
      "{'_id': '9',\n",
      " '_index': 'gb',\n",
      " '_score': 2.3835227,\n",
      " '_source': {'date': '2014-09-19',\n",
      "             'name': 'Mary Jones',\n",
      "             'tweet': 'Geo-location aggregations are really cool',\n",
      "             'user_id': 2},\n",
      " '_type': 'tweet'}\n"
     ]
    }
   ],
   "source": [
    "res = es.search(q='+name:(mary john) +date:>2014-09-10 +(aggregations geo)')\n",
    "print('Total hits:{}\\n'.format(res['hits']['total']))\n",
    "pprint(res['hits']['hits'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Terms' object has no attribute 'execute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-57811938e302>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'terms'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'geo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multi_match'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mary john'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_all'\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'range'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'gt'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'2014-09-10'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0maggs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'my_agg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'terms'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'geo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total hits:{}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tweet:{}, date:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/paulg/anaconda/lib/python3.5/site-packages/elasticsearch_dsl/utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             raise AttributeError(\n\u001b[0;32m--> 282\u001b[0;31m                 '%r object has no attribute %r' % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;31m# wrap nested dicts in AttrDict for convenient access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Terms' object has no attribute 'execute'"
     ]
    }
   ],
   "source": [
    "from elasticsearch_dsl import A\n",
    "a = A('terms', field='geo')\n",
    "s = Search(using=es) \\\n",
    "    .query('multi_match', query='mary john', fields='_all') \\\n",
    "    .filter('range', date={'gt': '2014-09-10'}) \\\n",
    "    .aggs.bucket(name='my_agg', agg_type='terms', field='geo')\n",
    "response = s.execute()\n",
    "print('Total hits:{}\\n'.format(response['hits']['total']))\n",
    "print('tweet:{}, date:{}'.format(response[0].tweet, response[0].date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\"range\": { \"publish_date\": { \"gte\": \"2015-01-01\" }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
